{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing: Segment audio files by class\n",
    "\n",
    "This is the first step in the data preprocessing pipeline. We break an audio file down into segments (1 second)\n",
    "\n",
    "This notebook processes long audio recordings (tapes) and their corresponding Audacity label files (TXT format) to extract segments for training an acoustic model. It supports **multi-class classification** where labels can be categorized into different classes based on their text content.\n",
    "\n",
    "**Class Handling:**\n",
    "1.  **Noise (Y=0)**: Extracted from time segments that *do not* contain any labeled sounds (gaps between annotations).\n",
    "2.  **Anemonefish (Target)**: Default class for all labeled segments that don't match other specific classes.\n",
    "3.  **Custom Classes** (e.g., \"biological\"): Labels that exactly match specific text in the annotation files are assigned to their respective classes.\n",
    "\n",
    "A sliding window approach is used to generate multiple audio clips from both labeled and noise regions.\n",
    "\n",
    "**New Features:**\n",
    "- **YAML Configuration**: All preprocessing parameters are loaded from a YAML config file for reproducibility.\n",
    "- **Flexible Directory Structure**: Audio files and annotations are now stored separately in `data/1_raw/{site}/audio/` and `data/1_raw/{site}/annotations/`.\n",
    "- **Multi-Class Support**: Configure any number of classes by specifying exact label text matches in the config.\n",
    "\n",
    "**Process:**\n",
    "1.  **Load Configuration**: Read all parameters from YAML config file (paths, classes, window settings).\n",
    "2.  **Parse Labels**: Read Audacity label files to identify time segments and their label text.\n",
    "3.  **Classify Segments**: Categorize labeled segments by class based on exact text matching.\n",
    "4.  **Identify Noise Regions**: Determine the time segments in the audio tapes that *do not* contain labeled sounds.\n",
    "5.  **Extract Segments with Sliding Window**:\n",
    "    *   Apply a sliding window to each class's labeled regions to generate class-specific examples.\n",
    "    *   Apply the same sliding window to the identified noise regions to generate negative examples.\n",
    "6.  **Save Segments**: Save the extracted audio clips as individual WAV files into class-specific output directories (e.g., `anemonefish/`, `biological/`, `noise/`).\n",
    "\n",
    "The output will populate class folders within `data/_cache/1_generate_training_audio/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import logging\n",
    "import random\n",
    "import yaml\n",
    "import shutil\n",
    "\n",
    "# Setup basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_cache(cache_dir_path):\n",
    "    \"\"\"\n",
    "    Clears the cache directory by removing all contents.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(cache_dir_path):\n",
    "        return \"Cache directory does not exist\"\n",
    "    \n",
    "    # Remove all contents of the directory\n",
    "    shutil.rmtree(cache_dir_path, ignore_errors=True)\n",
    "    \n",
    "    # Recreate the empty directory\n",
    "    os.makedirs(cache_dir_path, exist_ok=True)\n",
    "    \n",
    "    return \"Cache directory cleared\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "**YAML-Based Configuration**: All preprocessing parameters are now loaded from a YAML configuration file. This ensures reproducibility and makes it easy to version control your preprocessing settings.\n",
    "\n",
    "**To use this notebook:**\n",
    "1. Copy the template config: `data/2_training_datasets/preprocessing_config_template.yaml`\n",
    "2. Customize it for your dataset (update paths, classes, parameters)\n",
    "3. Update the `CONFIG_PATH` variable below to point to your config file\n",
    "4. Run the notebook!\n",
    "\n",
    "The YAML config specifies:\n",
    "- Dataset version and site information\n",
    "- Class list (e.g., `[\"noise\", \"anemonefish\"]` for binary, or `[\"noise\", \"anemonefish\", \"biological\"]` for multi-class)\n",
    "- Audio processing parameters (window size, slide duration, etc.)\n",
    "- Noise padding parameters (to prevent duration-based model bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Configuration from YAML ---\n",
    "\n",
    "# !!! UPDATE THIS PATH TO YOUR CONFIG FILE !!!\n",
    "CONFIG_PATH = '/Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/data/2_training_datasets/preprocessing_config_template.yaml'\n",
    "\n",
    "# Load configuration\n",
    "logging.info(f\"Loading configuration from: {CONFIG_PATH}\")\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Extract configuration values\n",
    "WORKSPACE_BASE_PATH = config['workspace_base_path']\n",
    "DATASET_VERSION = config['dataset_version']\n",
    "RAW_DATA_SITE = config['raw_data_site']\n",
    "ANNOTATION_VERSION = config['annotation_version']\n",
    "CLASSES = config['classes']\n",
    "\n",
    "# Construct paths based on new directory structure\n",
    "INPUT_AUDIO_DIR = os.path.join(WORKSPACE_BASE_PATH, 'data', '1_raw', RAW_DATA_SITE, 'audio')\n",
    "INPUT_ANNOTATIONS_DIR = os.path.join(WORKSPACE_BASE_PATH, 'data', '1_raw', RAW_DATA_SITE, ANNOTATION_VERSION)\n",
    "OUTPUT_AUDIO_FILES_DIR = os.path.join(WORKSPACE_BASE_PATH, 'data', '_cache', '1_generate_training_audio')\n",
    "\n",
    "# Audio processing parameters\n",
    "WINDOW_SIZE_SECONDS = config['audio_processing']['window_size_seconds']\n",
    "SLIDE_SECONDS = config['audio_processing']['slide_seconds']\n",
    "MIN_SEGMENT_DURATION_SECONDS = config['audio_processing']['min_segment_duration_seconds']\n",
    "\n",
    "# Noise padding parameters\n",
    "NOISE_PADDING_RATIO = config['noise_padding']['padding_ratio']\n",
    "MIN_NOISE_DURATION_FOR_SHORTENING = config['noise_padding']['min_duration_seconds']\n",
    "MAX_NOISE_DURATION_FOR_SHORTENING = config['noise_padding']['max_duration_seconds']\n",
    "\n",
    "# Create output directories for each class\n",
    "OUTPUT_CLASS_DIRS = {}\n",
    "for class_name in CLASSES:\n",
    "    class_dir = os.path.join(OUTPUT_AUDIO_FILES_DIR, class_name)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "    OUTPUT_CLASS_DIRS[class_name] = class_dir\n",
    "\n",
    "# Log configuration\n",
    "logging.info(f\"=== Configuration Loaded ===\")\n",
    "logging.info(f\"Dataset Version: {DATASET_VERSION}\")\n",
    "logging.info(f\"Raw Data Site: {RAW_DATA_SITE}\")\n",
    "logging.info(f\"Annotation Version: {ANNOTATION_VERSION}\")\n",
    "logging.info(f\"Classes: {CLASSES}\")\n",
    "logging.info(f\"Input Audio Directory: {INPUT_AUDIO_DIR}\")\n",
    "logging.info(f\"Input Annotations Directory: {INPUT_ANNOTATIONS_DIR}\")\n",
    "logging.info(f\"Output Base Directory: {OUTPUT_AUDIO_FILES_DIR}\")\n",
    "for class_name, class_dir in OUTPUT_CLASS_DIRS.items():\n",
    "    logging.info(f\"  - {class_name}: {class_dir}\")\n",
    "logging.info(f\"Audio Window Size: {WINDOW_SIZE_SECONDS}s\")\n",
    "logging.info(f\"Sliding Window Hop: {SLIDE_SECONDS}s\")\n",
    "logging.info(f\"Minimum Segment Duration: {MIN_SEGMENT_DURATION_SECONDS}s\")\n",
    "logging.info(f\"Noise Padding Ratio: {NOISE_PADDING_RATIO} ({int(NOISE_PADDING_RATIO*100)}%)\")\n",
    "\n",
    "# Validate input directories exist\n",
    "if not os.path.isdir(INPUT_AUDIO_DIR):\n",
    "    logging.critical(f\"Input audio directory not found: {INPUT_AUDIO_DIR}\")\n",
    "    logging.critical(\"Please check your configuration file.\")\n",
    "if not os.path.isdir(INPUT_ANNOTATIONS_DIR):\n",
    "    logging.critical(f\"Input annotations directory not found: {INPUT_ANNOTATIONS_DIR}\")\n",
    "    logging.critical(\"Please check your configuration file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_audacity_labels(label_file_path):\n",
    "    \"\"\"\n",
    "    Parses an Audacity label file (TXT, tab-separated).\n",
    "    Assumes columns are: start_time (s), end_time (s), label_text.\n",
    "    Returns a list of tuples representing labeled segments with their text: \n",
    "    [(start1, end1, label_text1), (start2, end2, label_text2), ...].\n",
    "    Labels are sorted by start time.\n",
    "    \"\"\"\n",
    "    labeled_segments = []\n",
    "    try:\n",
    "        # Read with tab delimiter, no header, read all three columns\n",
    "        df = pd.read_csv(label_file_path, sep='\\t', header=None, float_precision='round_trip')\n",
    "        for index, row in df.iterrows():\n",
    "            start_time = float(row[0])\n",
    "            end_time = float(row[1])\n",
    "            # Extract label text (third column), default to empty string if not present\n",
    "            label_text = str(row[2]).strip() if len(row) > 2 and pd.notna(row[2]) else \"\"\n",
    "            \n",
    "            if start_time < end_time: # Basic validation\n",
    "                 labeled_segments.append((start_time, end_time, label_text))\n",
    "            else:\n",
    "                logging.warning(f\"Skipping invalid segment in {label_file_path}: start_time {start_time} >= end_time {end_time}\")\n",
    "\n",
    "        # Sort segments by start time\n",
    "        labeled_segments.sort(key=lambda x: x[0])\n",
    "        logging.info(f\"Parsed {len(labeled_segments)} segments from {label_file_path}\")\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Label file not found: {label_file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        logging.warning(f\"Label file is empty: {label_file_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error parsing label file {label_file_path}: {e}\")\n",
    "    return labeled_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_labeled_segments(labeled_segments_with_text, classes):\n",
    "    \"\"\"\n",
    "    Classifies labeled segments into their respective classes based on label text matching.\n",
    "    \n",
    "    Args:\n",
    "        labeled_segments_with_text (list): List of tuples [(start, end, label_text), ...]\n",
    "        classes (list): List of class names from config (e.g., [\"noise\", \"anemonefish\", \"biological\"])\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary mapping class names to segment lists (without text)\n",
    "              {class_name: [(start1, end1), (start2, end2), ...]}\n",
    "    \n",
    "    Classification Logic:\n",
    "        - 'noise': Always represents unlabeled regions (handled separately, not from annotations)\n",
    "        - 'anemonefish': Default class for all labeled segments that don't match other classes\n",
    "        - Other classes: Exact match (case-sensitive) on label text\n",
    "    \"\"\"\n",
    "    # Initialize result dictionary for all non-noise classes\n",
    "    classified_segments = {}\n",
    "    for class_name in classes:\n",
    "        if class_name != 'noise':  # Noise is handled separately (unlabeled regions)\n",
    "            classified_segments[class_name] = []\n",
    "    \n",
    "    # Get list of specific class names to match (excluding 'noise' and 'anemonefish')\n",
    "    specific_classes = [c for c in classes if c not in ['noise', 'anemonefish']]\n",
    "    \n",
    "    # Classify each labeled segment\n",
    "    for start_time, end_time, label_text in labeled_segments_with_text:\n",
    "        matched = False\n",
    "        \n",
    "        # Try to match with specific classes (exact match, case-sensitive)\n",
    "        for specific_class in specific_classes:\n",
    "            if label_text == specific_class:\n",
    "                classified_segments[specific_class].append((start_time, end_time))\n",
    "                matched = True\n",
    "                break\n",
    "        \n",
    "        # If not matched with any specific class, assign to 'anemonefish' (default target class)\n",
    "        if not matched and 'anemonefish' in classified_segments:\n",
    "            classified_segments['anemonefish'].append((start_time, end_time))\n",
    "    \n",
    "    # Log classification results\n",
    "    for class_name, segments in classified_segments.items():\n",
    "        if segments:\n",
    "            logging.info(f\"  Classified {len(segments)} segments as '{class_name}'\")\n",
    "    \n",
    "    return classified_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_segments(total_duration_seconds, labeled_segments, min_segment_len_seconds):\n",
    "    \"\"\"\n",
    "    Identifies noise segments in an audio file given its total duration and labeled (non-noise) segments.\n",
    "    Args:\n",
    "        total_duration_seconds (float): Total duration of the audio file.\n",
    "        labeled_segments (list of tuples): Sorted list of (start, end) or (start, end, text) times for labeled regions.\n",
    "                                           Function handles both formats.\n",
    "        min_segment_len_seconds (float): Minimum duration for a segment to be considered noise.\n",
    "                                         Segments shorter than this will be ignored.\n",
    "    Returns:\n",
    "        list of tuples: [(noise_start1, noise_end1), ...] for noise regions.\n",
    "    \"\"\"\n",
    "    noise_segments = []\n",
    "    current_time = 0.0\n",
    "    \n",
    "    # Normalize labeled_segments to (start, end) format (handle both 2-tuple and 3-tuple)\n",
    "    normalized_segments = []\n",
    "    for seg in labeled_segments:\n",
    "        if len(seg) >= 2:\n",
    "            normalized_segments.append((seg[0], seg[1]))\n",
    "    \n",
    "    labeled_segments = normalized_segments\n",
    "\n",
    "    # If no labeled segments, the whole file is noise\n",
    "    if not labeled_segments:\n",
    "        if total_duration_seconds >= min_segment_len_seconds:\n",
    "            noise_segments.append((0.0, total_duration_seconds))\n",
    "            logging.info(f\"No labels found. Entire duration {total_duration_seconds:.2f}s considered noise for segmentation.\")\n",
    "        else:\n",
    "            logging.info(f\"No labels found. Entire duration {total_duration_seconds:.2f}s is less than min_segment_len_seconds {min_segment_len_seconds:.2f}s. No noise segments generated.\")\n",
    "        return noise_segments\n",
    "\n",
    "    # Process segment from start of tape to the first label\n",
    "    first_label_start = labeled_segments[0][0]\n",
    "    if first_label_start > current_time:\n",
    "        duration = first_label_start - current_time\n",
    "        if duration >= min_segment_len_seconds:\n",
    "            noise_segments.append((current_time, first_label_start))\n",
    "        # else: logging.debug(f\"Initial noise segment from {current_time:.2f} to {first_label_start:.2f} (duration {duration:.2f}s) too short.\")\n",
    "    current_time = max(current_time, labeled_segments[0][1]) # Move current time to end of first label\n",
    "\n",
    "    # Process segments between labels\n",
    "    for i in range(len(labeled_segments) - 1):\n",
    "        end_current_label = labeled_segments[i][1]\n",
    "        start_next_label = labeled_segments[i+1][0]\n",
    "        \n",
    "        # Ensure current_time is at least at the end of the current label before looking for a gap\n",
    "        current_time = max(current_time, end_current_label) \n",
    "\n",
    "        if start_next_label > current_time: # If there's a gap\n",
    "            duration = start_next_label - current_time\n",
    "            if duration >= min_segment_len_seconds:\n",
    "                noise_segments.append((current_time, start_next_label))\n",
    "            # else: logging.debug(f\"Noise segment between labels (from {current_time:.2f} to {start_next_label:.2f}, duration {duration:.2f}s) too short.\")\n",
    "        current_time = max(current_time, labeled_segments[i+1][1]) # Move current time to end of next label\n",
    "\n",
    "    # Process segment from the end of the last label to the end of the file\n",
    "    last_label_end = labeled_segments[-1][1]\n",
    "    current_time = max(current_time, last_label_end) # Ensure current_time is at least at the end of the last label\n",
    "    \n",
    "    if total_duration_seconds > current_time:\n",
    "        duration = total_duration_seconds - current_time\n",
    "        if duration >= min_segment_len_seconds:\n",
    "            noise_segments.append((current_time, total_duration_seconds))\n",
    "        # else: logging.debug(f\"Final noise segment (from {current_time:.2f} to {total_duration_seconds:.2f}, duration {duration:.2f}s) too short.\")\n",
    "            \n",
    "    if noise_segments:\n",
    "        logging.info(f\"Identified {len(noise_segments)} noise segments meeting minimum duration of {min_segment_len_seconds:.2f}s.\")\n",
    "    else:\n",
    "        logging.info(f\"No noise segments meeting minimum duration of {min_segment_len_seconds:.2f}s were identified.\")\n",
    "    return noise_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_save_segments_sliding_window(tape_audio_path, segments_to_process,\n",
    "                                         window_duration_s, slide_duration_s, sr,\n",
    "                                         output_dir_path, tape_basename, segment_type_prefix):\n",
    "    \"\"\"\n",
    "    Extracts audio segments using a sliding window from the given audio tape and saves them.\n",
    "    For 'anemonefish' type, segments shorter than window_duration_s will be padded with zeros.\n",
    "    For 'noise' type, sliding windows are extracted normally, then some windows are randomly shortened and padded.\n",
    "    Args:\n",
    "        tape_audio_path (str): Path to the full audio tape WAV file.\n",
    "        segments_to_process (list of tuples): List of (start_sec, end_sec) for regions to process.\n",
    "        window_duration_s (float): Duration of each window in seconds.\n",
    "        slide_duration_s (float): Hop duration for the sliding window in seconds.\n",
    "        sr (int): Sample rate of the audio tape.\n",
    "        output_dir_path (str): Directory to save the extracted audio windows.\n",
    "        tape_basename (str): Basename of the tape file, for naming windows.\n",
    "        segment_type_prefix (str): Prefix for the filename (e.g., 'noise', 'anemonefish').\n",
    "    Returns:\n",
    "        dict: Statistics containing counts of total windows, padded windows, and segment lengths.\n",
    "    \"\"\"\n",
    "    saved_windows_count = 0\n",
    "    padded_windows_count = 0\n",
    "    segment_lengths = []\n",
    "    window_len_samples = int(window_duration_s * sr)\n",
    "\n",
    "    if not segments_to_process:\n",
    "        logging.info(f\"No segments to process for {segment_type_prefix} from {tape_basename}.\")\n",
    "        return {\n",
    "            'total_windows': 0,\n",
    "            'padded_windows': 0,\n",
    "            'segment_lengths': []\n",
    "        }\n",
    "\n",
    "    for seg_idx, (seg_start_s, seg_end_s) in enumerate(segments_to_process):\n",
    "        segment_duration_s = seg_end_s - seg_start_s\n",
    "        segment_lengths.append(segment_duration_s)\n",
    "        \n",
    "        logging.debug(f\"Processing segment {seg_idx+1}/{len(segments_to_process)} ({segment_type_prefix}): \"\n",
    "                      f\"{seg_start_s:.2f}s - {seg_end_s:.2f}s (duration: {segment_duration_s:.2f}s) from {tape_basename}\")\n",
    "\n",
    "        if segment_duration_s <= 0:\n",
    "            logging.warning(f\"Segment {seg_idx+1} for {segment_type_prefix} from {tape_basename} has zero or negative duration. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Case 1: Segment is shorter than window_duration_s (for all non-noise classes)\n",
    "        # Noise segments use sliding window regardless of length to maintain variety\n",
    "        if segment_duration_s < window_duration_s and segment_type_prefix != \"noise\":\n",
    "            logging.info(f\"Segment {seg_idx+1} ({segment_type_prefix}, duration {segment_duration_s:.2f}s) is shorter than window size {window_duration_s:.2f}s. Padding...\")\n",
    "            start_sample = int(seg_start_s * sr)\n",
    "            frames_to_read = int(segment_duration_s * sr) # Read only the actual segment\n",
    "\n",
    "            if frames_to_read <= 0:\n",
    "                logging.warning(f\"Segment {seg_idx+1} ({segment_type_prefix}) resulted in {frames_to_read} frames to read. Skipping padding.\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                audio_segment_data, read_sr = sf.read(tape_audio_path, start=start_sample,\n",
    "                                                      frames=frames_to_read, dtype='float32', always_2d=False)\n",
    "                if sr != read_sr: # Should not happen if sf.info worked correctly\n",
    "                    logging.warning(f\"Sample rate mismatch during read: expected {sr}, got {read_sr}. Using original sr for padding calculation.\")\n",
    "\n",
    "                # Ensure audio_segment_data is 1D array\n",
    "                if audio_segment_data.ndim > 1:\n",
    "                    audio_segment_data = np.mean(audio_segment_data, axis=1) # Convert to mono by averaging if stereo\n",
    "\n",
    "                num_padding_samples = window_len_samples - len(audio_segment_data)\n",
    "                \n",
    "                if num_padding_samples < 0: # Should ideally not happen if segment_duration_s < window_duration_s\n",
    "                    logging.warning(f\"Calculated negative padding ({num_padding_samples}) for short segment {seg_idx+1}. \"\n",
    "                                    f\"Segment len: {len(audio_segment_data)}, target window len: {window_len_samples}. Clipping padding to 0.\")\n",
    "                    num_padding_samples = 0\n",
    "                    # Potentially truncate if audio_segment_data is somehow longer than window_len_samples\n",
    "                    audio_segment_data = audio_segment_data[:window_len_samples]\n",
    "\n",
    "                padded_audio_data = np.pad(audio_segment_data, (0, num_padding_samples), 'constant', constant_values=(0.0, 0.0))\n",
    "\n",
    "                if len(padded_audio_data) == window_len_samples:\n",
    "                    window_filename = f\"{tape_basename}_{segment_type_prefix}_window_padded_{saved_windows_count:04d}.wav\"\n",
    "                    output_window_path = os.path.join(output_dir_path, window_filename)\n",
    "                    sf.write(output_window_path, padded_audio_data, sr)\n",
    "                    saved_windows_count += 1\n",
    "                    padded_windows_count += 1  # Track padded window\n",
    "                else:\n",
    "                    logging.warning(f\"Padded audio for short segment {seg_idx+1} ({segment_type_prefix}) has unexpected length {len(padded_audio_data)} (expected {window_len_samples}). Skipping save.\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing/padding short segment {seg_idx+1} ({segment_type_prefix}) at {seg_start_s:.2f}s from {tape_audio_path}: {e}\", exc_info=True)\n",
    "            continue # Move to the next segment\n",
    "\n",
    "        # Case 2: Segment is >= window_duration_s OR noise segment (noise uses sliding window even for short segments)\n",
    "        # Apply sliding window approach to extract multiple overlapping windows\n",
    "        current_window_start_s = seg_start_s\n",
    "        while current_window_start_s + window_duration_s <= seg_end_s:\n",
    "            start_sample = int(current_window_start_s * sr)\n",
    "            \n",
    "            try:\n",
    "                audio_window_data, _ = sf.read(tape_audio_path, start=start_sample,\n",
    "                                               frames=window_len_samples, dtype='float32', always_2d=False)\n",
    "                \n",
    "                if audio_window_data.ndim > 1: # Ensure mono\n",
    "                    audio_window_data = np.mean(audio_window_data, axis=1)\n",
    "\n",
    "                if len(audio_window_data) == window_len_samples:\n",
    "                    # For noise segments, randomly decide whether to shorten and pad this window\n",
    "                    if segment_type_prefix == \"noise\" and random.random() < NOISE_PADDING_RATIO:\n",
    "                        # Randomly shorten this window and apply padding\n",
    "                        random_duration = random.uniform(MIN_NOISE_DURATION_FOR_SHORTENING, MAX_NOISE_DURATION_FOR_SHORTENING)\n",
    "                        random_samples = int(random_duration * sr)\n",
    "                        \n",
    "                        logging.info(f\"Randomly shortening noise window at {current_window_start_s:.2f}s (original duration {window_duration_s:.2f}s) to {random_duration:.2f}s for padding.\")\n",
    "                        \n",
    "                        # Truncate the window to the random duration\n",
    "                        shortened_audio_data = audio_window_data[:random_samples]\n",
    "                        \n",
    "                        # Pad to match the original window length\n",
    "                        num_padding_samples = window_len_samples - len(shortened_audio_data)\n",
    "                        \n",
    "                        if num_padding_samples < 0:\n",
    "                            logging.warning(f\"Calculated negative padding ({num_padding_samples}) for shortened noise window. Truncating.\")\n",
    "                            num_padding_samples = 0\n",
    "                            shortened_audio_data = shortened_audio_data[:window_len_samples]\n",
    "\n",
    "                        padded_audio_data = np.pad(shortened_audio_data, (0, num_padding_samples), 'constant', constant_values=(0.0, 0.0))\n",
    "                        \n",
    "                        if len(padded_audio_data) == window_len_samples:\n",
    "                            window_filename = f\"{tape_basename}_{segment_type_prefix}_window_padded_{saved_windows_count:04d}.wav\"\n",
    "                            output_window_path = os.path.join(output_dir_path, window_filename)\n",
    "                            sf.write(output_window_path, padded_audio_data, sr)\n",
    "                            saved_windows_count += 1\n",
    "                            padded_windows_count += 1  # Track padded window\n",
    "                        else:\n",
    "                            logging.warning(f\"Padded audio for shortened noise window has unexpected length {len(padded_audio_data)} (expected {window_len_samples}). Skipping save.\")\n",
    "                    else:\n",
    "                        # Save the normal window (for anemonefish or non-selected noise windows)\n",
    "                        window_filename = f\"{tape_basename}_{segment_type_prefix}_window_{saved_windows_count:04d}.wav\"\n",
    "                        output_window_path = os.path.join(output_dir_path, window_filename)\n",
    "                        sf.write(output_window_path, audio_window_data, sr)\n",
    "                        saved_windows_count += 1\n",
    "                else:\n",
    "                    logging.warning(f\"Could not read full window of {window_len_samples} samples \"\n",
    "                                    f\"at {current_window_start_s:.2f}s from {tape_basename} for sliding window. \"\n",
    "                                    f\"Read {len(audio_window_data)} samples. Skipping this window.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error reading/writing sliding window at {current_window_start_s:.2f}s \"\n",
    "                              f\"from {tape_audio_path} for {segment_type_prefix}: {e}\", exc_info=True)\n",
    "            \n",
    "            current_window_start_s += slide_duration_s\n",
    "            \n",
    "    logging.info(f\"Extracted and saved {saved_windows_count} '{segment_type_prefix}' windows from {tape_basename} (from {len(segments_to_process)} segments). Padded: {padded_windows_count}\")\n",
    "    \n",
    "    return {\n",
    "        'total_windows': saved_windows_count,\n",
    "        'padded_windows': padded_windows_count,\n",
    "        'segment_lengths': segment_lengths\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main Processing Loop\n",
    "\n",
    "This section iterates through all audio files in `INPUT_AUDIO_DIR`. For each audio tape:\n",
    "1. Finds matching annotation file(s) in `INPUT_ANNOTATIONS_DIR` based on filename matching.\n",
    "2. Parses the labels if the file exists; otherwise, treats the entire tape as noise.\n",
    "3. Classifies labeled segments into their respective classes based on label text matching.\n",
    "4. Identifies noise segments (unlabeled regions).\n",
    "5. Extracts and saves audio windows for each class into their respective output directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_processing():\n",
    "    if not os.path.isdir(INPUT_AUDIO_DIR):\n",
    "        logging.error(\"Input audio directory does not exist. Please check Configuration.\")\n",
    "        return\n",
    "    if not os.path.isdir(INPUT_ANNOTATIONS_DIR):\n",
    "        logging.error(\"Input annotations directory does not exist. Please check Configuration.\")\n",
    "        return\n",
    "\n",
    "    # Find all audio files\n",
    "    audio_files = glob.glob(os.path.join(INPUT_AUDIO_DIR, '*.wav')) + \\\n",
    "                  glob.glob(os.path.join(INPUT_AUDIO_DIR, '*.WAV'))\n",
    "    \n",
    "    if not audio_files:\n",
    "        logging.warning(f\"No .wav or .WAV files found in {INPUT_AUDIO_DIR}. Processing will not start.\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"Found {len(audio_files)} audio files for processing.\")\n",
    "    \n",
    "    # Initialize statistics tracking for all classes\n",
    "    class_stats = {}\n",
    "    for class_name in CLASSES:\n",
    "        class_stats[class_name] = {\n",
    "            'total_windows': 0,\n",
    "            'padded_windows': 0,\n",
    "            'segment_lengths': []\n",
    "        }\n",
    "\n",
    "    for audio_path in audio_files:\n",
    "        audio_basename_with_ext = os.path.basename(audio_path)\n",
    "        audio_basename = os.path.splitext(audio_basename_with_ext)[0]\n",
    "        \n",
    "        logging.info(f\"--- Processing audio: {audio_path} ---\")\n",
    "        \n",
    "        # Find matching annotation file(s) in the annotations directory\n",
    "        # Look for any .txt file that starts with the audio basename\n",
    "        annotation_pattern = os.path.join(INPUT_ANNOTATIONS_DIR, f\"{audio_basename}*.txt\")\n",
    "        annotation_files = glob.glob(annotation_pattern)\n",
    "        \n",
    "        # Filter out hidden files (starting with ._)\n",
    "        annotation_files = [f for f in annotation_files if not os.path.basename(f).startswith('._')]\n",
    "        \n",
    "        labeled_segments_with_text = [] # Initialize to empty list\n",
    "        if not annotation_files:\n",
    "            logging.warning(f\"No annotation file found for {audio_basename} in {INPUT_ANNOTATIONS_DIR}. \"\n",
    "                            \"This audio will only be processed for noise.\")\n",
    "        else:\n",
    "            # Use the first matching annotation file\n",
    "            annotation_file_path = annotation_files[0]\n",
    "            if len(annotation_files) > 1:\n",
    "                logging.info(f\"Multiple annotation files found for {audio_basename}, using: {os.path.basename(annotation_file_path)}\")\n",
    "            else:\n",
    "                logging.info(f\"Using annotation file: {os.path.basename(annotation_file_path)}\")\n",
    "            \n",
    "            labeled_segments_with_text = parse_audacity_labels(annotation_file_path)\n",
    "\n",
    "        try:\n",
    "            audio_info = sf.info(audio_path)\n",
    "            total_duration = audio_info.duration\n",
    "            sample_rate = audio_info.samplerate\n",
    "            logging.info(f\"Audio duration: {total_duration:.2f}s, Sample rate: {sample_rate}Hz\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Could not read audio info for {audio_path}: {e}\")\n",
    "            continue # Skip to the next audio file\n",
    "\n",
    "        # Classify labeled segments into their respective classes\n",
    "        if labeled_segments_with_text:\n",
    "            logging.info(f\"Classifying {len(labeled_segments_with_text)} labeled segments into classes...\")\n",
    "            classified_segments = classify_labeled_segments(labeled_segments_with_text, CLASSES)\n",
    "            \n",
    "            # Process each class's segments\n",
    "            for class_name in CLASSES:\n",
    "                if class_name == 'noise':\n",
    "                    continue  # Noise is handled separately below\n",
    "                \n",
    "                class_segments = classified_segments.get(class_name, [])\n",
    "                if class_segments:\n",
    "                    logging.info(f\"Processing {len(class_segments)} '{class_name}' segments from {audio_basename_with_ext}...\")\n",
    "                    \n",
    "                    stats = extract_save_segments_sliding_window(\n",
    "                        audio_path,\n",
    "                        class_segments,\n",
    "                        WINDOW_SIZE_SECONDS,\n",
    "                        SLIDE_SECONDS,\n",
    "                        sample_rate,\n",
    "                        OUTPUT_CLASS_DIRS[class_name],\n",
    "                        audio_basename,\n",
    "                        class_name\n",
    "                    )\n",
    "                    class_stats[class_name]['total_windows'] += stats['total_windows']\n",
    "                    class_stats[class_name]['padded_windows'] += stats['padded_windows']\n",
    "                    class_stats[class_name]['segment_lengths'].extend(stats['segment_lengths'])\n",
    "        else:\n",
    "            logging.info(f\"No labeled segments found for {audio_basename_with_ext}.\")\n",
    "\n",
    "        # Process Noise Segments (unlabeled regions)\n",
    "        noise_segments = get_noise_segments(total_duration, labeled_segments_with_text, MIN_SEGMENT_DURATION_SECONDS)\n",
    "        \n",
    "        if noise_segments:\n",
    "            logging.info(f\"Processing {len(noise_segments)} noise segments from {audio_basename_with_ext}...\")\n",
    "            noise_stats = extract_save_segments_sliding_window(\n",
    "                audio_path,\n",
    "                noise_segments,\n",
    "                WINDOW_SIZE_SECONDS,\n",
    "                SLIDE_SECONDS,\n",
    "                sample_rate,\n",
    "                OUTPUT_CLASS_DIRS['noise'],\n",
    "                audio_basename,\n",
    "                \"noise\"\n",
    "            )\n",
    "            class_stats['noise']['total_windows'] += noise_stats['total_windows']\n",
    "            class_stats['noise']['padded_windows'] += noise_stats['padded_windows']\n",
    "        else:\n",
    "            logging.info(f\"No suitable noise segments found in {audio_basename_with_ext}.\")\n",
    "        \n",
    "        logging.info(f\"--- Finished processing audio: {audio_basename_with_ext} ---\\n\")\n",
    "\n",
    "    # Calculate and display statistics\n",
    "    logging.info(f\"\\n=== Processing Complete ===\")\n",
    "    logging.info(f\"Dataset Version: {DATASET_VERSION}\")\n",
    "    logging.info(f\"\\nWindows Generated by Class:\")\n",
    "    \n",
    "    for class_name in CLASSES:\n",
    "        total_windows = class_stats[class_name]['total_windows']\n",
    "        padded_windows = class_stats[class_name]['padded_windows']\n",
    "        \n",
    "        logging.info(f\"\\n--- {class_name.upper()} ---\")\n",
    "        logging.info(f\"Total windows generated: {total_windows}\")\n",
    "        \n",
    "        if total_windows > 0:\n",
    "            padding_percentage = (padded_windows / total_windows) * 100\n",
    "            logging.info(f\"Padded windows: {padded_windows}/{total_windows} ({padding_percentage:.2f}%)\")\n",
    "        else:\n",
    "            logging.info(f\"No windows generated for this class\")\n",
    "        \n",
    "        # Display segment length statistics for non-noise classes\n",
    "        segment_lengths = class_stats[class_name]['segment_lengths']\n",
    "        if segment_lengths and class_name != 'noise':\n",
    "            import statistics\n",
    "            logging.info(f\"Segment length statistics:\")\n",
    "            logging.info(f\"  Total segments: {len(segment_lengths)}\")\n",
    "            logging.info(f\"  Mean: {statistics.mean(segment_lengths):.3f}s\")\n",
    "            logging.info(f\"  Median: {statistics.median(segment_lengths):.3f}s\")\n",
    "            logging.info(f\"  Min: {min(segment_lengths):.3f}s\")\n",
    "            logging.info(f\"  Max: {max(segment_lengths):.3f}s\")\n",
    "            if len(segment_lengths) > 1:\n",
    "                logging.info(f\"  Std Dev: {statistics.stdev(segment_lengths):.3f}s\")\n",
    "            \n",
    "            # Count segments shorter than window size\n",
    "            short_segments = [length for length in segment_lengths if length < WINDOW_SIZE_SECONDS]\n",
    "            if short_segments:\n",
    "                short_percentage = (len(short_segments) / len(segment_lengths)) * 100\n",
    "                logging.info(f\"  Segments < window size ({WINDOW_SIZE_SECONDS}s): {len(short_segments)}/{len(segment_lengths)} ({short_percentage:.2f}%)\")\n",
    "            else:\n",
    "                logging.info(f\"  All segments >= window size ({WINDOW_SIZE_SECONDS}s)\")\n",
    "    \n",
    "    logging.info(f\"\\n=== Summary ===\")\n",
    "    total_all_windows = sum(class_stats[c]['total_windows'] for c in CLASSES)\n",
    "    logging.info(f\"Total windows across all classes: {total_all_windows}\")\n",
    "    for class_name in CLASSES:\n",
    "        windows = class_stats[class_name]['total_windows']\n",
    "        if total_all_windows > 0:\n",
    "            percentage = (windows / total_all_windows) * 100\n",
    "            logging.info(f\"  {class_name}: {windows} ({percentage:.1f}%)\")\n",
    "        else:\n",
    "            logging.info(f\"  {class_name}: {windows}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Optional: Clear previous logs for a fresh run in notebook context if desired.\n",
    "    # for handler in logging.root.handlers[:]:\n",
    "    # logging.root.removeHandler(handler)\n",
    "    # logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') # Re-setup if cleared\n",
    "    \n",
    "    # Ensure basicConfig is called if not already (e.g. if cell with logging.basicConfig wasn't run prior in a session)\n",
    "    if not logging.getLogger().hasHandlers():\n",
    "         logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "            \n",
    "    main_processing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anemonefish_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21421d5d",
   "metadata": {},
   "source": [
    "## Updated preprocessing pipeline that uses spectogram data over image\n",
    "\n",
    "Previously, we have trained the machine learning model using (please make a link to 1-1, 1-2, 1-3 notebooks, and display each link text as 1-1[link for 1-1]) where we take the audio file, split it into the windows that are labelleed for each clas, turn into spectogram, plot with matplot lib, to turn into image, then save the image to a file, and load the image as a numpy array, this is how we trained the model on with that data. \n",
    "This notebook aims to change several of those preproceessing step by training the model on the specogram data befrore its passed to matplotlib to be turned into an image.\n",
    "Two key benefits:\n",
    "1. Much faster preprocessing due to vectoriseation of the windows\n",
    "2. Better training accuracy as we are prociign the raw sata to the ml model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "from src.anemonefish_acoustics.data import postprocess_prediction\n",
    "from src.anemonefish_acoustics.utils.logger import get_logger\n",
    "\n",
    "logging = get_logger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18bc394",
   "metadata": {},
   "source": [
    "## Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af93481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Configuration from YAML ---\n",
    "\n",
    "# !!! UPDATE THIS PATH TO YOUR CONFIG FILE !!!\n",
    "CONFIG_PATH = '/Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/data/2_training_datasets/preprocessing_config_template.yaml'\n",
    "\n",
    "# Load configuration\n",
    "logging.info(f\"Loading configuration from: {CONFIG_PATH}\")\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Extract configuration values\n",
    "WORKSPACE_BASE_PATH = config['workspace_base_path']\n",
    "DATASET_VERSION = config['dataset_version']\n",
    "RAW_DATA_SITE = config['raw_data_site']\n",
    "ANNOTATION_VERSION = config['annotation_version']\n",
    "CLASSES = config['classes']\n",
    "\n",
    "# Construct paths based on new directory structure\n",
    "INPUT_AUDIO_DIR = os.path.join(WORKSPACE_BASE_PATH, 'data', '1_raw', RAW_DATA_SITE, 'audio')\n",
    "INPUT_ANNOTATIONS_DIR = os.path.join(WORKSPACE_BASE_PATH, 'data', '1_raw', RAW_DATA_SITE, ANNOTATION_VERSION)\n",
    "OUTPUT_AUDIO_FILES_DIR = os.path.join(WORKSPACE_BASE_PATH, 'data', '_cache', '1_generate_training_audio')\n",
    "\n",
    "# Audio processing parameters\n",
    "WINDOW_SIZE_SECONDS = config['audio_processing']['window_size_seconds']\n",
    "SLIDE_SECONDS = config['audio_processing']['slide_seconds']\n",
    "MIN_SEGMENT_DURATION_SECONDS = config['audio_processing']['min_segment_duration_seconds']\n",
    "\n",
    "# Noise padding parameters\n",
    "NOISE_PADDING_RATIO = config['noise_padding']['padding_ratio']\n",
    "MIN_NOISE_DURATION_FOR_SHORTENING = config['noise_padding']['min_duration_seconds']\n",
    "MAX_NOISE_DURATION_FOR_SHORTENING = config['noise_padding']['max_duration_seconds']\n",
    "\n",
    "# Create output directories for each class\n",
    "OUTPUT_CLASS_DIRS = {}\n",
    "for class_name in CLASSES:\n",
    "    class_dir = os.path.join(OUTPUT_AUDIO_FILES_DIR, class_name)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "    OUTPUT_CLASS_DIRS[class_name] = class_dir\n",
    "\n",
    "# Log configuration\n",
    "logging.info(f\"=== Configuration Loaded ===\")\n",
    "logging.info(f\"Dataset Version: {DATASET_VERSION}\")\n",
    "logging.info(f\"Raw Data Site: {RAW_DATA_SITE}\")\n",
    "logging.info(f\"Annotation Version: {ANNOTATION_VERSION}\")\n",
    "logging.info(f\"Classes: {CLASSES}\")\n",
    "logging.info(f\"Input Audio Directory: {INPUT_AUDIO_DIR}\")\n",
    "logging.info(f\"Input Annotations Directory: {INPUT_ANNOTATIONS_DIR}\")\n",
    "logging.info(f\"Output Base Directory: {OUTPUT_AUDIO_FILES_DIR}\")\n",
    "for class_name, class_dir in OUTPUT_CLASS_DIRS.items():\n",
    "    logging.info(f\"  - {class_name}: {class_dir}\")\n",
    "logging.info(f\"Audio Window Size: {WINDOW_SIZE_SECONDS}s\")\n",
    "logging.info(f\"Sliding Window Hop: {SLIDE_SECONDS}s\")\n",
    "logging.info(f\"Minimum Segment Duration: {MIN_SEGMENT_DURATION_SECONDS}s\")\n",
    "logging.info(f\"Noise Padding Ratio: {NOISE_PADDING_RATIO} ({int(NOISE_PADDING_RATIO*100)}%)\")\n",
    "\n",
    "# Validate input directories exist\n",
    "if not os.path.isdir(INPUT_AUDIO_DIR):\n",
    "    logging.critical(f\"Input audio directory not found: {INPUT_AUDIO_DIR}\")\n",
    "    logging.critical(\"Please check your configuration file.\")\n",
    "if not os.path.isdir(INPUT_ANNOTATIONS_DIR):\n",
    "    logging.critical(f\"Input annotations directory not found: {INPUT_ANNOTATIONS_DIR}\")\n",
    "    logging.critical(\"Please check your configuration file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb96d73",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "1. Load audio file and classes data\n",
    "2. Split audio file into classes and noise\n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

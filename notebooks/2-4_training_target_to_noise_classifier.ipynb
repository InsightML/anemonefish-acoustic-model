{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Binary Spectrogram Classifier: Anemonefish vs. Noise\n",
    "\n",
    "This notebook trains a binary classification model to distinguish between spectrograms of anemonefish calls and background noise. \n",
    "\n",
    "Training data consists of two directories, one is spectograms of anemonefish, and the other is noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:57:50 - INFO - Logger initialized for anemonefish_acoustics.data.preprocessing\n",
      "12:57:50 - INFO - Monolith log file: /Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/logs/main.log\n",
      "12:57:50 - INFO - Error summary file: /Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/logs/error_summary.json\n",
      "12:57:50 - INFO - Logger initialized for binary_classifier\n",
      "12:57:50 - INFO - Monolith log file: /Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/logs/main.log\n",
      "12:57:50 - INFO - Error summary file: /Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/logs/error_summary.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_tuner\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('/Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/src')\n",
    "\n",
    "from anemonefish_acoustics.utils.logger import get_logger\n",
    "from anemonefish_acoustics.utils.utils import pretty_path\n",
    "from anemonefish_acoustics.models.hypermodels import TargetToNoiseHyperModel\n",
    "from anemonefish_acoustics.data.preprocessing import preprocess_audio_for_training\n",
    "\n",
    "# Setup logging - always use get_logger to ensure proper handlers\n",
    "logging = get_logger(name='binary_classifier', workspace_root='/Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:57:50 - INFO - TensorFlow is using the GPU!\n",
      "12:57:50 - INFO - Name: /physical_device:GPU:0, Type: GPU\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    logging.info(\"TensorFlow is using the GPU!\")\n",
    "    # You can print more details if needed\n",
    "    for gpu in tf.config.list_physical_devices('GPU'):\n",
    "        logging.info(f\"Name: {gpu.name}, Type: {gpu.device_type}\")\n",
    "else:\n",
    "    logging.warning(\"TensorFlow is NOT using the GPU. Training will be on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:57:50 - INFO - Loading configuration from: /Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/data/2_training_datasets/v2_biological/preprocessing_config_v2_biological_short.yaml\n",
      "12:57:50 - INFO - TensorBoard logs will be saved to: logs/experiments/target_to_noise_classifier/\n",
      "12:57:50 - INFO - Tuner logs will be saved to: Clown_Fish_Acoustics/logs/tuner/\n",
      "12:57:50 - INFO - Model checkpoints, config, and training results will be saved to: models/target_to_noise_classifier/\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "CONFIG_PATH = '/Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/data/2_training_datasets/v2_biological/preprocessing_config_v2_biological_short.yaml'\n",
    "\n",
    "# Ensure reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Load configuration\n",
    "logging.info(f\"Loading configuration from: {CONFIG_PATH}\")\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Extract configuration values\n",
    "WORKSPACE_BASE_PATH = Path(config['workspace_base_path'])\n",
    "DATASET_VERSION = config['dataset_version']\n",
    "DATA_SITE = config['raw_data_site']\n",
    "CLASSES = config['classes']\n",
    "ANNOTATION_VERSION = config['annotation_version']\n",
    "RAW_DATA_DIR = os.path.join(WORKSPACE_BASE_PATH, 'data', '1_raw', DATA_SITE)\n",
    "DATA_DIR = os.path.join(WORKSPACE_BASE_PATH, 'data', '2_training_datasets', DATASET_VERSION)\n",
    "\n",
    "ANNOTATION_DIR = os.path.join(RAW_DATA_DIR, ANNOTATION_VERSION)\n",
    "AUDIO_DIR = os.path.join(RAW_DATA_DIR, 'audio')\n",
    "\n",
    "MODEL_INPUT_SIZE = [config['spectrogram']['height_pixels'], config['spectrogram']['width_pixels'], 1]\n",
    "EPOCHS = config['epochs']\n",
    "TUNER_EPOCHS = config['tuner_epochs']\n",
    "MAX_TRIALS = config['max_trials']\n",
    "EXECUTIONS_PER_TRIAL = config['executions_per_trial']\n",
    "MODEL_SAVE_PATH = os.path.join(WORKSPACE_BASE_PATH, config['model_save_path'], config['project_name'])\n",
    "LEARNING_RATE = config['learning_rate']\n",
    "LOGS_DIR = os.path.join(WORKSPACE_BASE_PATH, config['logs_dir'], config['project_name'])\n",
    "TUNER_LOGS_DIR = os.path.join(WORKSPACE_BASE_PATH, config['tuner_logs_dir'])\n",
    "PROJECT_NAME = config['project_name']\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "os.makedirs(TUNER_LOGS_DIR, exist_ok=True)\n",
    "\n",
    "# Preprocessing parameters\n",
    "WINDOW_SIZE_SECONDS = config['audio_processing']['window_size_seconds']\n",
    "SLIDE_SIZE_SECONDS = config['audio_processing']['slide_size_seconds']\n",
    "N_FFT = config['spectrogram']['n_fft']\n",
    "HOP_LENGTH = config['spectrogram']['hop_length']\n",
    "SR_TARGET = config['spectrogram']['sr_target']\n",
    "\n",
    "# Noise padding parameters\n",
    "NOISE_PADDING_CONFIG = {\n",
    "    \"min_duration_s\": config['noise_padding']['min_duration_seconds'],\n",
    "    \"max_duration_s\": config['noise_padding']['max_duration_seconds'],\n",
    "    \"padding_ratio\": config['noise_padding']['padding_ratio']\n",
    "}\n",
    "\n",
    "# Logs\n",
    "logging.info(f\"TensorBoard logs will be saved to: {pretty_path(LOGS_DIR)}\")\n",
    "logging.info(f\"Tuner logs will be saved to: {pretty_path(TUNER_LOGS_DIR)}\")\n",
    "logging.info(f\"Model checkpoints, config, and training results will be saved to: {pretty_path(MODEL_SAVE_PATH, num_dirs=2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Val split & Class weight\n",
    "\n",
    "Here, we'll scan the specified directories for spectrogram images and assign labels based on their parent folder.\n",
    "- Images in `ANEMONEFISH_PATH` will be labeled as 'anemonefish' (1).\n",
    "- Images in `NOISE_PATH` will be labeled as 'noise' (0).\n",
    "---\n",
    "\n",
    "Plan:\n",
    "1. using CLASSES and DATA_DIR identify spectogram directory and list image paths for each class\n",
    "2. map X and Y dataset. Load X by loading all the images into an array. train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b: Raw spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:57:50 - INFO - Found 17 audio files in /Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/data/1_raw/papua_new_guines_2023/audio\n",
      "12:57:50 - INFO - Processing file pair: 20230210_000001_LL_B55_M_R_with labels.wav + 20230210_000001_LL_B55_M_R_with labels.txt\n",
      "12:57:50 - INFO - Parsed 349 segments from /Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/data/1_raw/papua_new_guines_2023/annotations/v2_biological_tag_short/20230210_000001_LL_B55_M_R_with labels.txt\n",
      "12:57:50 - INFO - Identified 323 noise segments meeting minimum duration of 0.10s.\n",
      "12:57:50 - INFO -   Classified 42 segments as 'anemonefish'\n",
      "12:57:50 - INFO -   Classified 307 segments as 'biological'\n",
      "12:57:50 - INFO - Segmented 42 segments for class anemonefish\n",
      "12:57:51 - INFO - Created 148 spectrograms for class anemonefish\n",
      "12:57:51 - INFO - Segmented 307 segments for class biological\n",
      "12:57:51 - INFO - Created 477 spectrograms for class biological\n",
      "12:57:51 - INFO - Segmented 323 segments for class noise\n",
      "12:57:52 - INFO - Created 1206 spectrograms for class noise\n",
      "12:57:52 - INFO - Processed 20230210_000001_LL_B55_M_R_with labels.wav: added 1831 spectrograms\n",
      "12:57:52 - INFO -   - anemonefish: 148 spectrograms\n",
      "12:57:52 - INFO -   - biological: 477 spectrograms\n",
      "12:57:52 - INFO -   - noise: 1206 spectrograms\n",
      "12:57:52 - INFO - Processing file pair: 20230217_040001_LL_B55_A_R_with labels_evaluation.wav + 20230217_040001_LL_B55_A_R_with labels_evaluation.txt\n",
      "12:57:52 - INFO - Parsed 175 segments from /Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/data/1_raw/papua_new_guines_2023/annotations/v2_biological_tag_short/20230217_040001_LL_B55_A_R_with labels_evaluation.txt\n",
      "12:57:52 - INFO - Identified 166 noise segments meeting minimum duration of 0.10s.\n",
      "12:57:52 - INFO -   Classified 12 segments as 'anemonefish'\n",
      "12:57:52 - INFO -   Classified 163 segments as 'biological'\n",
      "12:57:52 - INFO - Segmented 12 segments for class anemonefish\n",
      "12:57:52 - INFO - Created 31 spectrograms for class anemonefish\n",
      "12:57:52 - INFO - Segmented 163 segments for class biological\n",
      "12:57:52 - INFO - Created 373 spectrograms for class biological\n",
      "12:57:52 - INFO - Segmented 166 segments for class noise\n",
      "12:57:53 - INFO - Created 768 spectrograms for class noise\n",
      "12:57:53 - INFO - Processed 20230217_040001_LL_B55_A_R_with labels_evaluation.wav: added 1172 spectrograms\n",
      "12:57:53 - INFO -   - anemonefish: 31 spectrograms\n",
      "12:57:53 - INFO -   - biological: 373 spectrograms\n",
      "12:57:53 - INFO -   - noise: 768 spectrograms\n",
      "12:57:53 - INFO - Processing file pair: 20230302_000001_HG_B58_M_R_with labels_evaluation.wav + 20230302_000001_HG_B58_M_R_with labels_evaluation.txt\n",
      "12:57:53 - INFO - Parsed 118 segments from /Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/data/1_raw/papua_new_guines_2023/annotations/v2_biological_tag_short/20230302_000001_HG_B58_M_R_with labels_evaluation.txt\n",
      "12:57:53 - INFO - Identified 118 noise segments meeting minimum duration of 0.10s.\n",
      "12:57:53 - INFO -   Classified 7 segments as 'anemonefish'\n",
      "12:57:53 - INFO -   Classified 111 segments as 'biological'\n",
      "12:57:53 - INFO - Segmented 7 segments for class anemonefish\n",
      "12:57:53 - INFO - Created 12 spectrograms for class anemonefish\n",
      "12:57:53 - INFO - Segmented 111 segments for class biological\n",
      "12:57:53 - INFO - Created 220 spectrograms for class biological\n",
      "12:57:53 - INFO - Segmented 118 segments for class noise\n",
      "12:57:54 - INFO - Created 2103 spectrograms for class noise\n",
      "12:57:54 - INFO - Processed 20230302_000001_HG_B58_M_R_with labels_evaluation.wav: added 2335 spectrograms\n",
      "12:57:54 - INFO -   - anemonefish: 12 spectrograms\n",
      "12:57:54 - INFO -   - biological: 220 spectrograms\n",
      "12:57:54 - INFO -   - noise: 2103 spectrograms\n",
      "12:57:54 - WARNING - No annotation found for 20230302_050001_HG_B58_A_R_with labels.wav, skipping\n",
      "12:57:54 - WARNING - No annotation found for 20230302_050001_HG_LY394_A_NR_with labels_evaluation.wav, skipping\n",
      "12:57:54 - WARNING - No annotation found for 20230306_220150_Lui_B27_R_M_with labels_evaluation.wav, skipping\n",
      "12:57:54 - WARNING - No annotation found for 20230310_050025_LL_B10_A_R_with lables_A_R_evaluation.wav, skipping\n",
      "12:57:54 - WARNING - No annotation found for 20230310_230155_FirstB_B18_M_NR_with labels.wav, skipping\n",
      "12:57:54 - WARNING - No annotation found for 20230316_030015_GG2_B64_R_A_with labels_evaluation.wav, skipping\n",
      "12:57:54 - WARNING - No annotation found for 20230316_220150_GG2_B64_M_NB_with labels.wav, skipping\n",
      "12:57:54 - WARNING - No annotation found for 20230320_030015_Lui_B27_A_NR_with labels.wav, skipping\n",
      "12:57:54 - WARNING - No annotation found for 20230321_010005_First_B48_M_NR_with labels.wav, skipping\n",
      "12:57:54 - WARNING - No annotation found for 20230328_040020_bob_B68_A_NR_labels.wav, skipping\n",
      "12:57:54 - WARNING - No annotation found for 20230330_010005_FirstM_B47_M_NR_with labels.wav, skipping\n",
      "12:57:54 - WARNING - No annotation found for 20240531_040400_clarkii_LL_M400_NB.wav, skipping\n",
      "12:57:54 - WARNING - No annotation found for HG_LY394_M_R_with labels.wav, skipping\n",
      "12:57:54 - WARNING - No annotation found for LL_B10_A_NR audio with labels.wav, skipping\n",
      "12:57:54 - INFO - \n",
      "=== Processing Complete ===\n",
      "12:57:54 - INFO - Processed: 3 file pairs\n",
      "12:57:54 - INFO - Skipped: 14 files\n",
      "12:57:54 - INFO - noise: 4077 total spectrograms\n",
      "12:57:54 - INFO - anemonefish: 191 total spectrograms\n",
      "12:57:54 - INFO - biological: 1070 total spectrograms\n",
      "12:57:54 - INFO - Total spectrograms: 5338\n",
      "12:57:54 - INFO - Formatted training data: X shape = (5338, 256, 76), y shape = (5338, 3)\n",
      "12:57:54 - INFO -   Class 'noise' (index 0): 4077 samples\n",
      "12:57:54 - INFO -   Class 'anemonefish' (index 1): 191 samples\n",
      "12:57:54 - INFO -   Class 'biological' (index 2): 1070 samples\n",
      "12:57:54 - INFO - X shape after adding channel dimension and transposing for Conv2D layers: (5338, 76, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "X, y, class_mappings = preprocess_audio_for_training(\n",
    "    audio_dir=AUDIO_DIR,\n",
    "    annotations_dir=ANNOTATION_DIR,\n",
    "    window_duration_s=WINDOW_SIZE_SECONDS,\n",
    "    slide_duration_s=SLIDE_SIZE_SECONDS,\n",
    "    sr_target=SR_TARGET,\n",
    "    n_fft=N_FFT,\n",
    "    hop_length=None,\n",
    "    logger=logging,\n",
    "    classes=CLASSES,\n",
    "    min_segment_len_seconds=0.1,\n",
    "    noise_padding_params=NOISE_PADDING_CONFIG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:\n",
      "  noise (index 0): 0.4364\n",
      "  anemonefish (index 1): 9.3159\n",
      "  biological (index 2): 1.6629\n"
     ]
    }
   ],
   "source": [
    "# Convert one-hot encoded labels back to class indices\n",
    "y_class_indices = np.argmax(y, axis=1)  # Converts [0,1,0] -> 1, [1,0,0] -> 0, etc.\n",
    "\n",
    "# Calculate class weights for balanced training \n",
    "class_weights_array = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_class_indices),\n",
    "    y=y_class_indices)\n",
    "\n",
    "# Convert array to dictionary for tf training\n",
    "class_weights_dict = {i: class_weights_array[i] for i in range(len(class_weights_array))}\n",
    "\n",
    "# Log the class weights\n",
    "print(\"Class weights:\")\n",
    "for class_idx, weight in class_weights_dict.items():\n",
    "    class_name = class_mappings[class_idx]\n",
    "    print(f\"  {class_name} (index {class_idx}): {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:57:55 - INFO - X_train: (4270, 76, 256, 1)\n",
      "12:57:55 - INFO - X_val: (1068, 76, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split X and Y into train, val, test\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, y, test_size=config['validation_size'], random_state=config['seed'], stratify=y)\n",
    "\n",
    "logging.info(f\"X_train: {X_train.shape}\")\n",
    "logging.info(f\"X_val: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create tf.data Datasets\n",
    "\n",
    "Create optimized tf.data datasets using the shared preprocessing module and calculate class weights for balanced training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 12:57:55.131232: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-11-08 12:57:55.131260: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2025-11-08 12:57:55.131263: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 14.04 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762606675.131274  751054 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1762606675.131289  751054 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = (tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "                   .shuffle(buffer_size=len(X_train),\n",
    "                           seed=config['seed'],\n",
    "                           reshuffle_each_iteration=True)\n",
    "                   .batch(config['batch_size'])\n",
    "                   .cache()\n",
    "                   .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "\n",
    "val_dataset = (tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "                 .batch(config['batch_size'])\n",
    "                 .cache()\n",
    "                 .prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:57:55 - INFO - Testing tf.data pipeline...\n",
      "12:57:55 - INFO - ✓ Successfully loaded batch:\n",
      "12:57:55 - INFO -   - X shape: (32, 76, 256, 1)\n",
      "12:57:55 - INFO -   - Y shape: (32, 3)\n",
      "12:57:55 - INFO -   - X value range: [0.000, 1.000]\n",
      "12:57:55 - INFO -   - X dtype: <dtype: 'float64'>\n",
      "12:57:55 - INFO -   - Y dtype: <dtype: 'float64'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 12:57:55.381167: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Test the dataset pipeline with a single batch\n",
    "if train_dataset is not None:\n",
    "    logging.info(\"Testing tf.data pipeline...\")\n",
    "    try:\n",
    "        sample_batch = next(iter(train_dataset.take(1)))\n",
    "        spectrograms, labels = sample_batch\n",
    "        logging.info(\"✓ Successfully loaded batch:\")\n",
    "        logging.info(f\"  - X shape: {spectrograms.shape}\")\n",
    "        logging.info(f\"  - Y shape: {labels.shape}\")\n",
    "        logging.info(f\"  - X value range: [{tf.reduce_min(spectrograms):.3f}, {tf.reduce_max(spectrograms):.3f}]\")\n",
    "        logging.info(f\"  - X dtype: {spectrograms.dtype}\")\n",
    "        logging.info(f\"  - Y dtype: {labels.dtype}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"✗ Error testing pipeline: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define callbacks\n",
    "We'll use several Keras callbacks during training:\n",
    "- `ModelCheckpoint`: To save the best model based on validation loss.\n",
    "- `EarlyStopping`: To stop training if the validation loss doesn't improve for a certain number of epochs.\n",
    "- `ReduceLROnPlateau`: To reduce the learning rate if validation loss plateaus.\n",
    "- `TensorBoard`: To log training metrics and graphs for visualization with TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:57:55 - INFO - Existing runs: ['run_2', 'run_5', 'run_1', 'run_3', 'run_4', 'run_6', 'run_7', 'run_8', 'run_9', 'run_10', 'run_11', 'run_12']\n",
      "12:57:55 - INFO - TensorBoard logs will be saved to: /Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/logs/experiments/target_to_noise_classifier/run_13\n",
      "12:57:55 - INFO - Model checkpoints will be saved to: /Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/models/target_to_noise_classifier/run_13\n",
      "12:57:55 - INFO - Best model will be saved as: /Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/models/target_to_noise_classifier/run_13/best_model.keras\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Create a unique directory for this training run's logs and checkpoints\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# Get number of existing runs\n",
    "existing_runs = [d for d in os.listdir(LOGS_DIR) if d.startswith('run_')]\n",
    "logging.info(f\"Existing runs: {existing_runs}\")\n",
    "next_run_number = len(existing_runs) + 1\n",
    "\n",
    "run_log_dir = os.path.join(LOGS_DIR, f\"run_{next_run_number}\")\n",
    "run_checkpoint_dir = os.path.join(MODEL_SAVE_PATH, f\"run_{next_run_number}\")\n",
    "\n",
    "os.makedirs(run_log_dir, exist_ok=True)\n",
    "os.makedirs(run_checkpoint_dir, exist_ok=True)\n",
    "\n",
    "best_model_path = os.path.join(run_checkpoint_dir, \"best_model.keras\") # Using .keras format\n",
    "\n",
    "# Callbacks\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=run_log_dir, histogram_freq=0)\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=best_model_path,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss', # Save the model with the best validation loss\n",
    "    mode='min',         # The lower the validation loss, the better\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50, # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,\n",
    "    restore_best_weights=True # Restores model weights from the epoch with the best value of the monitored quantity.\n",
    ")\n",
    "\n",
    "reduce_lr_callback = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2, # Factor by which the learning rate will be reduced. new_lr = lr * factor\n",
    "    patience=5,  # Number of epochs with no improvement after which learning rate will be reduced.\n",
    "    min_lr=1e-6, # Lower bound on the learning rate.\n",
    "    verbose=1\n",
    ")\n",
    "callbacks_list = [\n",
    "    tensorboard_callback,\n",
    "    model_checkpoint_callback,\n",
    "    early_stopping_callback,\n",
    "    reduce_lr_callback\n",
    "]\n",
    "callbacks_list_tuner = [\n",
    "    tensorboard_callback,\n",
    "    reduce_lr_callback\n",
    "]\n",
    "\n",
    "logging.info(f\"TensorBoard logs will be saved to: {run_log_dir}\")\n",
    "logging.info(f\"Model checkpoints will be saved to: {run_checkpoint_dir}\")\n",
    "logging.info(f\"Best model will be saved as: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 train and tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Start the search (tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:05:24 - INFO - Hypermodel input shape: [76, 256, 1],  X shape: (32, 76, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the hypermodel\n",
    "hypermodel = TargetToNoiseHyperModel(input_shape=MODEL_INPUT_SIZE, num_classes=len(CLASSES))\n",
    "logging.info(f\"Hypermodel input shape: {MODEL_INPUT_SIZE},  X shape: {spectrograms.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid'], 'ordered': False}\n",
      "cnn_depth (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 6, 'step': 1, 'sampling': 'linear'}\n",
      "use_dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the tuner\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=hypermodel,\n",
    "    objective='val_loss',\n",
    "    max_trials=MAX_TRIALS,\n",
    "    executions_per_trial=EXECUTIONS_PER_TRIAL,\n",
    "    directory=TUNER_LOGS_DIR,\n",
    "    project_name=PROJECT_NAME\n",
    ")\n",
    "tuner.search_space_summary(extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTUNER_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list_tuner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m      4\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during tuning.search: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(begin_step)\n\u001b[0;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    219\u001b[0m     ):\n\u001b[0;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[1;32m    914\u001b[0m   filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    915\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(\n\u001b[1;32m    916\u001b[0m           bound_args\n\u001b[1;32m    917\u001b[0m       )\n\u001b[1;32m    918\u001b[0m   )\n\u001b[0;32m--> 919\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    920\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds):\n\u001b[1;32m    925\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/anemonefish_model/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tuner.search(train_dataset, epochs=TUNER_EPOCHS, validation_data=val_dataset, callbacks=callbacks_list_tuner, class_weight=class_weights_dict)\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during tuning.search: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 query the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=2)\n",
    "model = models[0]\n",
    "model.summary()\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "# Use the hypermodel instance to build the model with best hyperparameters\n",
    "model = hypermodel.build(best_hps)\n",
    "\n",
    "# Train with the full epoch count\n",
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    epochs=EPOCHS, \n",
    "    validation_data=val_dataset, \n",
    "    callbacks=callbacks_list,\n",
    "    class_weight=class_weights_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "logging.info(\"Saving the trained model...\")\n",
    "\n",
    "# Create model directory if it doesn't exist\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "\n",
    "# Save the model in Keras format (.keras)\n",
    "model_save_file = os.path.join(MODEL_SAVE_PATH, 'model.keras')\n",
    "model.save(model_save_file)\n",
    "logging.info(f\"Model saved to: {model_save_file}\")\n",
    "\n",
    "# Also save model weights separately (optional)\n",
    "weights_save_file = os.path.join(MODEL_SAVE_PATH, 'weights.weights.h5')\n",
    "model.save_weights(weights_save_file)\n",
    "logging.info(f\"Model weights saved to: {weights_save_file}\")\n",
    "\n",
    "# Save training history\n",
    "history_save_file = os.path.join(MODEL_SAVE_PATH, 'training_history.npy')\n",
    "np.save(history_save_file, history.history)\n",
    "logging.info(f\"Training history saved to: {history_save_file}\")\n",
    "\n",
    "# Save model configuration for reference\n",
    "model_config = {\n",
    "    'input_shape': MODEL_INPUT_SIZE,\n",
    "    'num_classes': len(CLASSES),\n",
    "    'classes': CLASSES,\n",
    "    'epochs_trained': len(history.history['loss']),\n",
    "    'final_train_loss': history.history['loss'][-1],\n",
    "    'final_val_loss': history.history['val_loss'][-1],\n",
    "    'final_train_accuracy': history.history['accuracy'][-1],\n",
    "    'final_val_accuracy': history.history['val_accuracy'][-1]\n",
    "}\n",
    "\n",
    "config_save_file = os.path.join(MODEL_SAVE_PATH, 'model_config.yaml')\n",
    "with open(config_save_file, 'w') as f:\n",
    "    yaml.dump(model_config, f, default_flow_style=False)\n",
    "logging.info(f\"Model configuration saved to: {config_save_file}\")\n",
    "\n",
    "logging.info(\"✅ Model saving completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Evaluate the Model\n",
    "\n",
    "After training, we'll evaluate the model's performance on the unseen test set.\n",
    "We will:\n",
    "- Load the best weights saved during training (if `restore_best_weights=True` in `EarlyStopping`, this is already done).\n",
    "- Make predictions on the test set.\n",
    "- Calculate and display key metrics like accuracy, precision, recall, F1-score, and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If EarlyStopping with restore_best_weights=True was used, \n",
    "# # the model already has the best weights. Otherwise, load them:\n",
    "# if os.path.exists(best_model_path):\n",
    "#     logging.info(f\"Loading best model weights from: {best_model_path}\")\n",
    "#     model.load_weights(best_model_path)\n",
    "# else:\n",
    "#     logging.warning(\"Best model checkpoint not found. Evaluating with current model weights.\")\n",
    "\n",
    "# if test_dataset is not None:\n",
    "#     logging.info(\"Evaluating model on the test set using tf.data...\")\n",
    "    \n",
    "#     # Use the test dataset directly for prediction and evaluation\n",
    "#     y_pred_probs = model.predict(test_dataset, verbose=1)\n",
    "#     y_pred_test = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "    \n",
    "#     # Get true labels (we already have them from the data split)\n",
    "#     y_true_test = test_labels\n",
    "    \n",
    "#     # Calculate metrics using the test dataset\n",
    "#     test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_dataset, verbose=0)\n",
    "    \n",
    "#     logging.info(f\"Test Loss: {test_loss:.4f}\")\n",
    "#     logging.info(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "#     logging.info(f\"Test Precision: {test_precision:.4f}\")\n",
    "#     logging.info(f\"Test Recall: {test_recall:.4f}\")\n",
    "\n",
    "#     logging.info(\"Classification Report on Test Set:\")\n",
    "#     logging.info(f\"\\n{classification_report(y_true_test, y_pred_test, target_names=CLASS_NAMES)}\")\n",
    "\n",
    "#     logging.info(\"Confusion Matrix on Test Set:\")\n",
    "#     cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "#     logging.info(f\"\\n{cm}\")\n",
    "\n",
    "#     # Plotting the confusion matrix\n",
    "#     fig, ax = plt.subplots(figsize=(6, 6))\n",
    "#     cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
    "#     fig.colorbar(cax)\n",
    "#     ax.set_xlabel('Predicted Labels')\n",
    "#     ax.set_ylabel('True Labels')\n",
    "#     ax.set_title('Confusion Matrix')\n",
    "#     ax.xaxis.set_ticklabels([''] + CLASS_NAMES) # Add empty string for 0-tick\n",
    "#     ax.yaxis.set_ticklabels([''] + CLASS_NAMES) # Add empty string for 0-tick\n",
    "    \n",
    "#     # Annotate cells with counts\n",
    "#     for i in range(cm.shape[0]):\n",
    "#         for j in range(cm.shape[1]):\n",
    "#             ax.text(j, i, str(cm[i, j]), va='center', ha='center', color='black' if cm[i,j] < (cm.max()/2) else 'white')\n",
    "            \n",
    "#     plt.show()\n",
    "\n",
    "# else:\n",
    "#     logging.warning(\"Test dataset is not available. Skipping evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualize Training History\n",
    "\n",
    "Plotting the training and validation accuracy and loss helps to understand the model's learning process and identify potential issues like overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'history' in locals() and history is not None:\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history.get('val_accuracy') # Use .get() in case validation was skipped\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history.get('val_loss') # Use .get()\n",
    "\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot Training and Validation Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    if val_acc:\n",
    "        plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    # Plot Training and Validation Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    if val_loss:\n",
    "        plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    logging.warning(\"Training history not available. Skipping visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save the Final Model (Optional)\n",
    "\n",
    "The `ModelCheckpoint` callback already saved the best performing model during training.\n",
    "This step is to explicitly save the model's final state (which might be different from the best if `restore_best_weights=False` or if you continued training after early stopping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tf2onnx\n",
    "# import tensorflow as tf # Required for tf.TensorSpec and if 'model' is tf.keras.Model\n",
    "\n",
    "# # It's assumed that 'model', 'best_model_path', 'MODEL_SAVE_PATH', \n",
    "# # and 'current_time' are defined in previous cells of your notebook.\n",
    "\n",
    "# # The best model is already saved by ModelCheckpoint (likely in Keras format)\n",
    "# logging.info(f\"The best performing Keras model (from ModelCheckpoint) was saved to: {best_model_path}\")\n",
    "\n",
    "# # Define the path for the ONNX model\n",
    "# # This uses the directory from MODEL_SAVE_PATH and the current_time string, similar to original logic\n",
    "# onnx_model_dir = os.path.dirname(run_checkpoint_dir)\n",
    "# onnx_model_filename = f\"model.onnx\"\n",
    "# onnx_model_save_path = os.path.join(onnx_model_dir, onnx_model_filename)\n",
    "\n",
    "# logging.info(f\"Preparing to save the final model in ONNX format to: {onnx_model_save_path}\")\n",
    "\n",
    "# try:\n",
    "#     # Convert the Keras model to ONNX.\n",
    "#     # 'model' should be your trained tf.keras.Model instance.\n",
    "    \n",
    "#     # For many common models, tf2onnx can infer the input signature.\n",
    "#     # If conversion fails, you may need to explicitly provide the input_signature.\n",
    "#     # ----- Example for explicitly defining input_signature -----\n",
    "#     # # Replace (None, height, width, channels) with your model's actual input shape and dtype.\n",
    "#     # # For a model with input shape (e.g., 128, 128, 1) for spectrograms:\n",
    "#     # input_signature = [tf.TensorSpec(shape=(None, 128, 128, 1), dtype=tf.float32, name=\"input_spectrogram\")]\n",
    "#     #\n",
    "#     # # If your model has multiple inputs, provide a list of tf.TensorSpec objects.\n",
    "#     # # You can also try to derive it dynamically from the model (might need adjustments):\n",
    "#     # # if hasattr(model, 'inputs') and model.inputs:\n",
    "#     # #     input_signature = [tf.TensorSpec.from_tensor(tensor) for tensor in model.inputs]\n",
    "#     # # else:\n",
    "#     # #     logging.info(\"Could not automatically determine input signature from model.inputs. You may need to define it manually.\")\n",
    "#     # #     input_signature = None # Fallback to tf2onnx inference\n",
    "#     # ----- End of example -----\n",
    "\n",
    "#     # For now, we'll let tf2onnx try to infer the input signature.\n",
    "#     # If this fails, define 'input_signature' using the examples above.\n",
    "#     input_signature = None \n",
    "\n",
    "#     logging.info(\"Starting Keras to ONNX conversion...\")\n",
    "#     # Ensure the 'model' variable holds your trained Keras model\n",
    "#     model_proto, external_tensor_storage = tf2onnx.convert.from_keras(\n",
    "#         model=model,\n",
    "#         input_signature=input_signature,\n",
    "#         opset=13,  # Opset 13 is a common choice; adjust if needed for compatibility\n",
    "#         output_path=onnx_model_save_path\n",
    "#     )\n",
    "#     logging.info(f\"Successfully saved model in ONNX format to: {onnx_model_save_path}\")\n",
    "\n",
    "# except ImportError:\n",
    "#     logging.error(\"The 'tf2onnx' library was not found.\")\n",
    "#     logging.error(\"Please install it, for example, by running: pip install tf2onnx\")\n",
    "# except AttributeError as ae:\n",
    "#     if 'model' in str(ae):\n",
    "#         logging.error(\"The 'model' variable is likely not defined or is not a Keras model.\")\n",
    "#         logging.error(\"Ensure 'model' is your trained Keras model instance before this cell.\")\n",
    "#     else:\n",
    "#         logging.error(f\"An AttributeError occurred: {ae}\")\n",
    "#         logging.error(\"This might be due to an issue with the model structure or tf2onnx.\")\n",
    "# except Exception as e:\n",
    "#     logging.error(f\"An error occurred during Keras to ONNX conversion: {e}\")\n",
    "#     logging.error(\"Tips for troubleshooting:\")\n",
    "#     logging.error(\"- Ensure 'tf2onnx' and its dependencies (like 'onnx') are installed and up to date (`pip install -U tf2onnx onnx`).\")\n",
    "#     logging.error(\"- If the error mentions input shapes, types, or names, you most likely need to define the 'input_signature' argument for `tf2onnx.convert.from_keras` explicitly.\")\n",
    "#     logging.error(\"  See the commented-out 'Example for explicitly defining input_signature' in the code above.\")\n",
    "#     logging.error(\"  Adjust the shape (e.g., `(None, 128, 128, 1)`), `dtype` (e.g., `tf.float32`), and `name` to match your model's input layer(s).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anemonefish_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

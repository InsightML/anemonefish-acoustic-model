{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Spectrogram Classifier: Anemonefish vs. Noise\n",
    "\n",
    "This notebook trains a binary classification model to distinguish between spectrograms of anemonefish calls and background noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from PIL import Image\n",
    "import cv2 # OpenCV for image processing, used by albumentations\n",
    "import albumentations as A\n",
    "from glob import glob\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/src')\n",
    "\n",
    "from anemonefish_acoustics.utils.logger import get_logger\n",
    "\n",
    "# Setup logging\n",
    "logging = get_logger()\n",
    "\n",
    "# Ensure reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    logging.info(\"TensorFlow is using the GPU!\")\n",
    "    # You can print more details if needed\n",
    "    for gpu in tf.config.list_physical_devices('GPU'):\n",
    "        logging.info(f\"Name: {gpu.name}, Type: {gpu.device_type}\")\n",
    "else:\n",
    "    logging.warning(\"TensorFlow is NOT using the GPU. Training will be on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "\n",
    "# Paths - Adjust these to your actual data locations\n",
    "BASE_DATA_PATH = '/Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/data/1_binary_training_data/spectograms' # Base directory for spectrograms\n",
    "ANEMONEFISH_SPECS_PATH = os.path.join(BASE_DATA_PATH, 'anemonefish') # Spectrograms of anemonefish\n",
    "NOISE_SPECS_PATH = os.path.join(BASE_DATA_PATH, 'noise')             # Spectrograms of noise\n",
    "\n",
    "LOGS_DIR = '/Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/logs/experiments/binary_classifier_spectrogram'\n",
    "MODEL_SAVE_PATH = '/Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/models/binary_classifier/'\n",
    "\n",
    "# Image and Model Parameters\n",
    "IMG_WIDTH = 256  # Assuming square spectrograms, adjust if needed\n",
    "IMG_HEIGHT = 256 # Assuming square spectrograms, adjust if needed\n",
    "IMG_CHANNELS = 3 # Typically RGB, even if spectrograms are grayscale, they are often loaded/processed as RGB\n",
    "MODEL_INPUT_SIZE = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "# Training Hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50 # Start with a moderate number, can be adjusted\n",
    "LEARNING_RATE = 1e-3\n",
    "VALIDATION_SPLIT = 0.1 # 10% of training data for validation\n",
    "TEST_SPLIT = 0.1       # 10% of total data for final testing\n",
    "\n",
    "# Labels\n",
    "CLASS_NAMES = ['noise', 'anemonefish']\n",
    "LABEL_MAP = {'noise': 0, 'anemonefish': 1}\n",
    "\n",
    "logging.info(\"Configuration Loaded.\")\n",
    "logging.info(f\"Anemonefish Spectrogram Path: {ANEMONEFISH_SPECS_PATH}\")\n",
    "logging.info(f\"Noise Spectrogram Path: {NOISE_SPECS_PATH}\")\n",
    "logging.info(f\"Model Input Size: {MODEL_INPUT_SIZE}\")\n",
    "logging.info(f\"Batch Size: {BATCH_SIZE}\")\n",
    "\n",
    "# Check if spectrogram directories exist\n",
    "if not os.path.isdir(ANEMONEFISH_SPECS_PATH):\n",
    "    logging.warning(f\"Anemonefish spectrogram directory not found: {ANEMONEFISH_SPECS_PATH}\")\n",
    "    logging.warning(\"Please ensure your anemonefish spectrograms are in the correct path.\")\n",
    "if not os.path.isdir(NOISE_SPECS_PATH):\n",
    "    logging.warning(f\"Noise spectrogram directory not found: {NOISE_SPECS_PATH}\")\n",
    "    logging.warning(\"Please ensure your noise spectrograms are in the correct path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data Paths and Labels\n",
    "\n",
    "Here, we'll scan the specified directories for spectrogram images and assign labels based on their parent folder.\n",
    "- Images in `ANEMONEFISH_SPECS_PATH` will be labeled as 'anemonefish' (1).\n",
    "- Images in `NOISE_SPECS_PATH` will be labeled as 'noise' (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filepaths_and_labels(base_path, class_name, label_map):\n",
    "    \"\"\"Loads image file paths and assigns labels.\"\"\"\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    class_dir = os.path.join(base_path, class_name)\n",
    "    \n",
    "    if not os.path.isdir(class_dir):\n",
    "        logging.warning(f\"Directory not found for class '{class_name}': {class_dir}\")\n",
    "        return filepaths, labels\n",
    "        \n",
    "    for filename in os.listdir(class_dir):\n",
    "        if not filename.startswith('.') and filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            filepaths.append(os.path.join(class_dir, filename))\n",
    "            labels.append(label_map[class_name])\n",
    "    logging.info(f\"Found {len(filepaths)} images for class '{class_name}' in {class_dir}\")\n",
    "    return filepaths, labels\n",
    "\n",
    "# Load anemonefish spectrograms\n",
    "anemonefish_files, anemonefish_labels = load_filepaths_and_labels(BASE_DATA_PATH, 'anemonefish', LABEL_MAP)\n",
    "\n",
    "# Load noise spectrograms\n",
    "noise_files, noise_labels = load_filepaths_and_labels(BASE_DATA_PATH, 'noise', LABEL_MAP)\n",
    "\n",
    "# Combine data\n",
    "all_filepaths = anemonefish_files + noise_files\n",
    "all_labels = anemonefish_labels + noise_labels\n",
    "\n",
    "if not all_filepaths:\n",
    "    logging.critical(\"No image files were found. Please check your ANEMONEFISH_SPECS_PATH and NOISE_SPECS_PATH in the configuration.\")\n",
    "    # You might want to stop execution here if no data is found.\n",
    "    # For now, we'll proceed, but the generator and training will fail.\n",
    "else:\n",
    "    logging.info(f\"Total images found: {len(all_filepaths)}\")\n",
    "    logging.info(f\"Total labels: {len(all_labels)}\")\n",
    "    logging.info(f\"Unique labels: {np.unique(all_labels)}\")\n",
    "    logging.info(f\"Label distribution: {dict(zip(*np.unique(all_labels, return_counts=True)))}\")  # Shows counts per class\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_filepaths = np.array(all_filepaths)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train, Validation, and Test Split\n",
    "\n",
    "We'll split the data into training, validation, and testing sets.\n",
    "- First, separate a test set.\n",
    "- Then, split the remaining data into training and validation sets.\n",
    "This ensures the test set is completely unseen during training and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(all_filepaths) > 0:\n",
    "    # Step 1: Split into training+validation and test sets\n",
    "    train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
    "        all_filepaths,\n",
    "        all_labels,\n",
    "        test_size=TEST_SPLIT,\n",
    "        random_state=SEED,\n",
    "        stratify=all_labels  # Important for imbalanced datasets\n",
    "    )\n",
    "\n",
    "    # Step 2: Split training+validation into training and validation sets\n",
    "    # Adjust validation_split relative to the size of train_val_paths\n",
    "    effective_validation_split = VALIDATION_SPLIT / (1 - TEST_SPLIT) if (1 - TEST_SPLIT) > 0 else 0\n",
    "\n",
    "    if len(train_val_paths) > 1 and effective_validation_split > 0 : # Ensure there's enough data to split\n",
    "        train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "            train_val_paths,\n",
    "            train_val_labels,\n",
    "            test_size=effective_validation_split,\n",
    "            random_state=SEED,\n",
    "            stratify=train_val_labels # Important for imbalanced datasets\n",
    "        )\n",
    "    else: # Not enough data for a validation split after test split, or validation split is zero\n",
    "        logging.warning(\"Not enough data for a separate validation set after test split, or VALIDATION_SPLIT is 0. Validation set will be empty or same as training.\")\n",
    "        train_paths, train_labels = train_val_paths, train_val_labels\n",
    "        val_paths, val_labels = np.array([]), np.array([]) # Empty validation set\n",
    "\n",
    "\n",
    "    logging.info(f\"Training samples: {len(train_paths)}\")\n",
    "    logging.info(f\"Validation samples: {len(val_paths)}\")\n",
    "    logging.info(f\"Test samples: {len(test_paths)}\")\n",
    "\n",
    "    # Verify distribution in splits (optional)\n",
    "    if len(train_labels) > 0:\n",
    "        logging.info(f\"Train label distribution: {dict(zip(*np.unique(train_labels, return_counts=True)))}\")\n",
    "    if len(val_labels) > 0:\n",
    "        logging.info(f\"Validation label distribution: {dict(zip(*np.unique(val_labels, return_counts=True)))}\")\n",
    "    if len(test_labels) > 0:\n",
    "        logging.info(f\"Test label distribution: {dict(zip(*np.unique(test_labels, return_counts=True)))}\")\n",
    "else:\n",
    "    logging.warning(\"Skipping data splitting as no data was loaded.\")\n",
    "    train_paths, val_paths, test_paths = np.array([]), np.array([]), np.array([])\n",
    "    train_labels, val_labels, test_labels = np.array([]), np.array([]), np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Calculate class weights\n",
    "# This needs to be done only if train_labels are available and not empty\n",
    "if 'train_labels' in globals() and len(train_labels) > 0:\n",
    "    class_weights_array = class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(train_labels),\n",
    "        y=train_labels\n",
    "    )\n",
    "    # Keras expects class_weight as a dictionary\n",
    "    class_weights_dict = {i : class_weights_array[i] for i in range(len(class_weights_array))}\n",
    "    logging.info(f\"Calculated class weights: {class_weights_dict}\")\n",
    "else:\n",
    "    class_weights_dict = None\n",
    "    logging.warning(\"Skipping class weight calculation as train_labels are not available or empty.\")\n",
    "    logging.warning(\"If training proceeds, it will be without class weights.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Augmentation and Preprocessing Pipeline\n",
    "\n",
    "We'll use `albumentations` for preprocessing. For now, this will primarily involve resizing and normalization.\n",
    "We define separate pipelines for training (which could include augmentation later) and validation/testing (which only does necessary preprocessing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For binary classification, we don't need keypoint_params like in your example.\n",
    "\n",
    "# Training Augmentations / Preprocessing\n",
    "# Initially, this will just be resizing and normalization.\n",
    "# We can add more augmentations like RandomBrightnessContrast, ShiftScaleRotate later if needed.\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(height=IMG_HEIGHT, width=IMG_WIDTH, interpolation=cv2.INTER_AREA),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0) # Typical ImageNet stats\n",
    "    # ToTensorV2() # Albumentations can also convert to tensor, but Keras Sequence usually handles numpy\n",
    "])\n",
    "\n",
    "# Validation/Test Preprocessing (no random augmentations)\n",
    "val_test_transform = A.Compose([\n",
    "    A.Resize(height=IMG_HEIGHT, width=IMG_WIDTH, interpolation=cv2.INTER_AREA),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0)\n",
    "    # ToTensorV2()\n",
    "])\n",
    "\n",
    "logging.info(\"Augmentation/Preprocessing pipelines defined.\")\n",
    "logging.info(f\"Images will be resized to: ({IMG_HEIGHT}, {IMG_WIDTH}) and normalized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Generator (Keras Sequence)\n",
    "\n",
    "We'll create a custom Keras `Sequence` to load and preprocess images on-the-fly. This is memory-efficient, especially for large datasets.\n",
    "The generator will take file paths and labels, load images, apply the defined transformations, and yield batches of (image, label) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramDataGenerator(Sequence):\n",
    "    def __init__(self,\n",
    "                 image_paths,\n",
    "                 labels,\n",
    "                 batch_size,\n",
    "                 input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
    "                 transform=None,\n",
    "                 shuffle=True):\n",
    "        self.image_paths = np.array(image_paths)\n",
    "        self.labels = np.array(labels)\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.transform = transform\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.image_paths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate one batch of data\n",
    "        # Generate indexes of the batch\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Find list of IDs (paths) and corresponding labels\n",
    "        batch_image_paths = self.image_paths[batch_indexes]\n",
    "        batch_labels = self.labels[batch_indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X = np.empty((self.batch_size, *self.input_size), dtype=np.float32)\n",
    "        y = np.empty((self.batch_size), dtype=np.int64) # For binary classification, labels are single integers\n",
    "\n",
    "        for i, img_path in enumerate(batch_image_paths):\n",
    "            try:\n",
    "                # Load image using PIL (handles various formats, ensures 3 channels if needed)\n",
    "                img = Image.open(img_path).convert('RGB') # Convert to RGB\n",
    "                img_array = np.array(img)\n",
    "\n",
    "                if self.transform:\n",
    "                    augmented = self.transform(image=img_array)\n",
    "                    img_array_processed = augmented['image']\n",
    "                else:\n",
    "                    # Basic resize if no albumentations transform (should not happen with our setup)\n",
    "                    img_array_processed = cv2.resize(img_array, (self.input_size[1], self.input_size[0]))\n",
    "                    img_array_processed = img_array_processed / 255.0 # Basic normalization if not using albumentations\n",
    "\n",
    "                X[i,] = img_array_processed\n",
    "                y[i] = batch_labels[i]\n",
    "                \n",
    "            except FileNotFoundError:\n",
    "                logging.error(f\"Image file not found at {img_path}. Skipping.\")\n",
    "                # Potentially fill with zeros or a placeholder, or skip and adjust batch size\n",
    "                # For simplicity, we'll just have this sample missing if an error occurs.\n",
    "                # A more robust solution would handle this more gracefully.\n",
    "                X[i,] = np.zeros(self.input_size, dtype=np.float32)\n",
    "                y[i] = 0 # Or some default label\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing image {img_path}: {e}. Skipping.\")\n",
    "                X[i,] = np.zeros(self.input_size, dtype=np.float32)\n",
    "                y[i] = 0\n",
    "\n",
    "\n",
    "        # For binary_crossentropy, labels should be (batch_size,) and model output (batch_size, 1) with sigmoid\n",
    "        # Or labels can be one-hot encoded (batch_size, num_classes) for categorical_crossentropy\n",
    "        # Here, we are using simple integer labels for binary classification with from_logits=False or direct sigmoid.\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Updates indexes after each epoch\n",
    "        self.indexes = np.arange(len(self.image_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "logging.info(\"SpectrogramDataGenerator class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Data Generators\n",
    "\n",
    "Instantiate the data generators for training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train_paths) > 0 :\n",
    "    train_generator = SpectrogramDataGenerator(\n",
    "        image_paths=train_paths,\n",
    "        labels=train_labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        input_size=MODEL_INPUT_SIZE,\n",
    "        transform=train_transform,\n",
    "        shuffle=True\n",
    "    )\n",
    "    logging.info(f\"Train generator created with {len(train_generator)} batches.\")\n",
    "else:\n",
    "    train_generator = None\n",
    "    logging.warning(\"Train generator not created as there are no training paths.\")\n",
    "\n",
    "if len(val_paths) > 0:\n",
    "    validation_generator = SpectrogramDataGenerator(\n",
    "        image_paths=val_paths,\n",
    "        labels=val_labels,\n",
    "        batch_size=BATCH_SIZE, # Can use a different batch size for validation if desired\n",
    "        input_size=MODEL_INPUT_SIZE,\n",
    "        transform=val_test_transform,\n",
    "        shuffle=False # No need to shuffle validation data\n",
    "    )\n",
    "    logging.info(f\"Validation generator created with {len(validation_generator)} batches.\")\n",
    "else:\n",
    "    validation_generator = None\n",
    "    logging.warning(\"Validation generator not created as there are no validation paths.\")\n",
    "\n",
    "if len(test_paths) > 0:\n",
    "    test_generator = SpectrogramDataGenerator(\n",
    "        image_paths=test_paths,\n",
    "        labels=test_labels,\n",
    "        batch_size=1, # Typically batch size 1 for testing\n",
    "        input_size=MODEL_INPUT_SIZE,\n",
    "        transform=val_test_transform,\n",
    "        shuffle=False # No need to shuffle test data\n",
    "    )\n",
    "    logging.info(f\"Test generator created with {len(test_generator)} batches (samples).\")\n",
    "else:\n",
    "    test_generator = None\n",
    "    logging.warning(\"Test generator not created as there are no test paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Define the CNN Model\n",
    "\n",
    "We'll define a simple Convolutional Neural Network (CNN) suitable for binary image classification.\n",
    "The architecture will consist of a few convolutional blocks followed by dense layers.\n",
    "- Convolutional layers for feature extraction.\n",
    "- MaxPooling layers for down-sampling.\n",
    "- BatchNormalization for stabilizing learning.\n",
    "- Dropout for regularization.\n",
    "- A final Dense layer with a sigmoid activation for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_cnn(input_shape):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "\n",
    "        # Block 1\n",
    "        Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # Block 2\n",
    "        Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # Block 3\n",
    "        Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        # Block 4\n",
    "        Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid') # Sigmoid activation for binary classification\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model = create_binary_cnn(MODEL_INPUT_SIZE)\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compile the Model\n",
    "\n",
    "Compile the model by specifying the optimizer, loss function, and metrics.\n",
    "- **Optimizer**: Adam is a good default choice.\n",
    "- **Loss Function**: `binary_crossentropy` is appropriate for binary classification with a sigmoid output.\n",
    "- **Metrics**: `accuracy` is a common metric for classification. We can also add others like Precision and Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')])\n",
    "\n",
    "logging.info(\"Model compiled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Define Callbacks and Train the Model\n",
    "\n",
    "We'll use several Keras callbacks during training:\n",
    "- `ModelCheckpoint`: To save the best model based on validation loss.\n",
    "- `EarlyStopping`: To stop training if the validation loss doesn't improve for a certain number of epochs.\n",
    "- `ReduceLROnPlateau`: To reduce the learning rate if validation loss plateaus.\n",
    "- `TensorBoard`: To log training metrics and graphs for visualization with TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Create a unique directory for this training run's logs and checkpoints\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# Get number of existing runs\n",
    "existing_runs = [d for d in os.listdir(LOGS_DIR) if d.startswith('run_')]\n",
    "next_run_number = len(existing_runs) + 1\n",
    "\n",
    "run_log_dir = os.path.join(LOGS_DIR, f\"run_{next_run_number}\")\n",
    "run_checkpoint_dir = os.path.join(MODEL_SAVE_PATH, f\"checkpoints_run_{next_run_number}\")\n",
    "\n",
    "os.makedirs(run_log_dir, exist_ok=True)\n",
    "os.makedirs(run_checkpoint_dir, exist_ok=True)\n",
    "\n",
    "best_model_path = os.path.join(run_checkpoint_dir, \"best_model.keras\") # Using .keras format\n",
    "\n",
    "# Callbacks\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=run_log_dir, histogram_freq=1)\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=best_model_path,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss', # Save the model with the best validation loss\n",
    "    mode='min',         # The lower the validation loss, the better\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50, # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,\n",
    "    restore_best_weights=True # Restores model weights from the epoch with the best value of the monitored quantity.\n",
    ")\n",
    "\n",
    "reduce_lr_callback = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2, # Factor by which the learning rate will be reduced. new_lr = lr * factor\n",
    "    patience=5,  # Number of epochs with no improvement after which learning rate will be reduced.\n",
    "    min_lr=1e-6, # Lower bound on the learning rate.\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks_list = [\n",
    "    tensorboard_callback,\n",
    "    model_checkpoint_callback,\n",
    "    early_stopping_callback,\n",
    "    reduce_lr_callback\n",
    "]\n",
    "\n",
    "logging.info(f\"TensorBoard logs will be saved to: {run_log_dir}\")\n",
    "logging.info(f\"Model checkpoints will be saved to: {run_checkpoint_dir}\")\n",
    "logging.info(f\"Best model will be saved as: {best_model_path}\")\n",
    "\n",
    "# Check if generators are valid before starting training\n",
    "if train_generator is None:\n",
    "    logging.critical(\"Training generator is not available. Cannot start training.\")\n",
    "elif validation_generator is None:\n",
    "    logging.warning(\"Validation generator is not available. Training will proceed without validation, which is not recommended.\")\n",
    "    # Optionally, you could decide to not train, or train with a subset of training data as validation.\n",
    "    # For now, we'll allow training without validation if the user explicitly set it up this way.\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks_list, # Some callbacks might depend on validation data (e.g. ModelCheckpoint on val_loss)\n",
    "        class_weight=class_weights_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "else:\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=callbacks_list,\n",
    "        class_weight=class_weights_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "    logging.info(\"Training finished.\")\n",
    "    # Load the best weights saved by ModelCheckpoint (if EarlyStopping didn't already restore them)\n",
    "    # model.load_weights(best_model_path) # Redundant if restore_best_weights=True in EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Evaluate the Model\n",
    "\n",
    "After training, we'll evaluate the model's performance on the unseen test set.\n",
    "We will:\n",
    "- Load the best weights saved during training (if `restore_best_weights=True` in `EarlyStopping`, this is already done).\n",
    "- Make predictions on the test set.\n",
    "- Calculate and display key metrics like accuracy, precision, recall, F1-score, and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"/Volumes/InsightML/NAS/3_Lucia_Yllan/Clown_Fish_Acoustics/models/binary_classifier/checkpoints_run_3/best_model.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If EarlyStopping with restore_best_weights=True was used, \n",
    "# the model already has the best weights. Otherwise, load them:\n",
    "if os.path.exists(best_model_path):\n",
    "    logging.info(f\"Loading best model weights from: {best_model_path}\")\n",
    "    model.load_weights(best_model_path)\n",
    "else:\n",
    "    logging.warning(\"Best model checkpoint not found. Evaluating with current model weights.\")\n",
    "\n",
    "if test_generator is not None and len(test_generator) > 0:\n",
    "    logging.info(\"Evaluating model on the test set...\")\n",
    "    \n",
    "    # Get true labels from the test generator\n",
    "    # Note: test_generator batch_size is 1, so test_labels are directly usable.\n",
    "    # If batch_size was > 1, you'd need to iterate through the generator to collect all labels.\n",
    "    y_true_test = test_labels \n",
    "    \n",
    "    # Make predictions\n",
    "    # The predict method of the model expects the data directly, \n",
    "    # and our test_generator yields (images, labels)\n",
    "    # We need to collect all images from the test_generator first.\n",
    "    \n",
    "    num_test_samples = len(test_paths)\n",
    "    X_test = np.empty((num_test_samples, *MODEL_INPUT_SIZE), dtype=np.float32)\n",
    "    \n",
    "    for i in range(num_test_samples): # test_generator has batch_size 1\n",
    "        img_batch, _ = test_generator[i] # Get the i-th batch (which is a single image)\n",
    "        X_test[i] = img_batch[0] # img_batch is (1, H, W, C), so take the first element\n",
    "\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred_test = (y_pred_probs > 0.5).astype(int).flatten() # Convert probabilities to binary predictions (0 or 1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    test_loss, test_accuracy, test_precision, test_recall = model.evaluate(X_test, y_true_test, verbose=0)\n",
    "    \n",
    "    logging.info(f\"Test Loss: {test_loss:.4f}\")\n",
    "    logging.info(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    logging.info(f\"Test Precision: {test_precision:.4f}\")\n",
    "    logging.info(f\"Test Recall: {test_recall:.4f}\")\n",
    "\n",
    "    logging.info(\"Classification Report on Test Set:\")\n",
    "    logging.info(f\"\\n{classification_report(y_true_test, y_pred_test, target_names=CLASS_NAMES)}\")\n",
    "\n",
    "    logging.info(\"Confusion Matrix on Test Set:\")\n",
    "    cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "    logging.info(f\"\\n{cm}\")\n",
    "\n",
    "    # Plotting the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels([''] + CLASS_NAMES) # Add empty string for 0-tick\n",
    "    ax.yaxis.set_ticklabels([''] + CLASS_NAMES) # Add empty string for 0-tick\n",
    "    \n",
    "    # Annotate cells with counts\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, str(cm[i, j]), va='center', ha='center', color='black' if cm[i,j] < (cm.max()/2) else 'white')\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    logging.warning(\"Test generator is not available or empty. Skipping evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualize Training History\n",
    "\n",
    "Plotting the training and validation accuracy and loss helps to understand the model's learning process and identify potential issues like overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'history' in locals() and history is not None:\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history.get('val_accuracy') # Use .get() in case validation was skipped\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history.get('val_loss') # Use .get()\n",
    "\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot Training and Validation Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    if val_acc:\n",
    "        plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    # Plot Training and Validation Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    if val_loss:\n",
    "        plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    logging.warning(\"Training history not available. Skipping visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save the Final Model (Optional)\n",
    "\n",
    "The `ModelCheckpoint` callback already saved the best performing model during training.\n",
    "This step is to explicitly save the model's final state (which might be different from the best if `restore_best_weights=False` or if you continued training after early stopping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tf2onnx\n",
    "import tensorflow as tf # Required for tf.TensorSpec and if 'model' is tf.keras.Model\n",
    "\n",
    "# It's assumed that 'model', 'best_model_path', 'MODEL_SAVE_PATH', \n",
    "# and 'current_time' are defined in previous cells of your notebook.\n",
    "\n",
    "# The best model is already saved by ModelCheckpoint (likely in Keras format)\n",
    "logging.info(f\"The best performing Keras model (from ModelCheckpoint) was saved to: {best_model_path}\")\n",
    "\n",
    "# Define the path for the ONNX model\n",
    "# This uses the directory from MODEL_SAVE_PATH and the current_time string, similar to original logic\n",
    "onnx_model_dir = os.path.dirname(run_checkpoint_dir)\n",
    "onnx_model_filename = f\"model.onnx\"\n",
    "onnx_model_save_path = os.path.join(onnx_model_dir, onnx_model_filename)\n",
    "\n",
    "logging.info(f\"Preparing to save the final model in ONNX format to: {onnx_model_save_path}\")\n",
    "\n",
    "try:\n",
    "    # Convert the Keras model to ONNX.\n",
    "    # 'model' should be your trained tf.keras.Model instance.\n",
    "    \n",
    "    # For many common models, tf2onnx can infer the input signature.\n",
    "    # If conversion fails, you may need to explicitly provide the input_signature.\n",
    "    # ----- Example for explicitly defining input_signature -----\n",
    "    # # Replace (None, height, width, channels) with your model's actual input shape and dtype.\n",
    "    # # For a model with input shape (e.g., 128, 128, 1) for spectrograms:\n",
    "    # input_signature = [tf.TensorSpec(shape=(None, 128, 128, 1), dtype=tf.float32, name=\"input_spectrogram\")]\n",
    "    #\n",
    "    # # If your model has multiple inputs, provide a list of tf.TensorSpec objects.\n",
    "    # # You can also try to derive it dynamically from the model (might need adjustments):\n",
    "    # # if hasattr(model, 'inputs') and model.inputs:\n",
    "    # #     input_signature = [tf.TensorSpec.from_tensor(tensor) for tensor in model.inputs]\n",
    "    # # else:\n",
    "    # #     logging.info(\"Could not automatically determine input signature from model.inputs. You may need to define it manually.\")\n",
    "    # #     input_signature = None # Fallback to tf2onnx inference\n",
    "    # ----- End of example -----\n",
    "\n",
    "    # For now, we'll let tf2onnx try to infer the input signature.\n",
    "    # If this fails, define 'input_signature' using the examples above.\n",
    "    input_signature = None \n",
    "\n",
    "    logging.info(\"Starting Keras to ONNX conversion...\")\n",
    "    # Ensure the 'model' variable holds your trained Keras model\n",
    "    model_proto, external_tensor_storage = tf2onnx.convert.from_keras(\n",
    "        model=model,\n",
    "        input_signature=input_signature,\n",
    "        opset=13,  # Opset 13 is a common choice; adjust if needed for compatibility\n",
    "        output_path=onnx_model_save_path\n",
    "    )\n",
    "    logging.info(f\"Successfully saved model in ONNX format to: {onnx_model_save_path}\")\n",
    "\n",
    "except ImportError:\n",
    "    logging.error(\"The 'tf2onnx' library was not found.\")\n",
    "    logging.error(\"Please install it, for example, by running: pip install tf2onnx\")\n",
    "except AttributeError as ae:\n",
    "    if 'model' in str(ae):\n",
    "        logging.error(\"The 'model' variable is likely not defined or is not a Keras model.\")\n",
    "        logging.error(\"Ensure 'model' is your trained Keras model instance before this cell.\")\n",
    "    else:\n",
    "        logging.error(f\"An AttributeError occurred: {ae}\")\n",
    "        logging.error(\"This might be due to an issue with the model structure or tf2onnx.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred during Keras to ONNX conversion: {e}\")\n",
    "    logging.error(\"Tips for troubleshooting:\")\n",
    "    logging.error(\"- Ensure 'tf2onnx' and its dependencies (like 'onnx') are installed and up to date (`pip install -U tf2onnx onnx`).\")\n",
    "    logging.error(\"- If the error mentions input shapes, types, or names, you most likely need to define the 'input_signature' argument for `tf2onnx.convert.from_keras` explicitly.\")\n",
    "    logging.error(\"  See the commented-out 'Example for explicitly defining input_signature' in the code above.\")\n",
    "    logging.error(\"  Adjust the shape (e.g., `(None, 128, 128, 1)`), `dtype` (e.g., `tf.float32`), and `name` to match your model's input layer(s).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anemonefish_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

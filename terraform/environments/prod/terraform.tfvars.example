# Example Terraform variables for prod environment
# Copy this to terraform.tfvars and customize

project_name = "anemonefish-inference"

# Model configuration
model_s3_bucket = "your-model-artifacts-bucket"
model_s3_key    = "models/v1.0/best_model.keras"
model_version   = "v1.0"

# Lambda image URI (required in prod - use specific version tag)
lambda_image_uri = "123456789012.dkr.ecr.us-east-1.amazonaws.com/anemonefish-inference-prod:v1.0.0"

# Lambda concurrency (optional)
# lambda_reserved_concurrent_executions = 10

# CORS configuration (restrict to your frontend domain)
cors_allowed_origins = [
  "https://your-frontend-domain.com",
  "https://www.your-frontend-domain.com"
]

# API key authentication
enable_api_key = true

# Inference configuration (optional - uses defaults if not specified)
inference_config = {
  fmax_hz              = 2000
  n_fft                = 1024
  hop_length           = 256
  width_pixels         = 256
  height_pixels        = 256
  window_duration      = 1.0
  stride_duration      = 0.4
  batch_size           = 32
  confidence_threshold = 0.5
  target_class         = "anemonefish"
  min_event_duration   = 0.2
  min_gap_duration     = 0.1
  smoothing_window     = 5
  model_classes        = "noise,anemonefish,biological"
}

# Tags
tags = {
  Owner       = "ml-team"
  CostCenter  = "production"
  Project     = "anemonefish-acoustics"
}
